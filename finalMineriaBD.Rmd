---
title: "Examen_Final_DIP"
author: '150074'
date: "6/12/2017"
output: html_document
---

#Examen Final Minería de Datos Agosto Diciembre 2017
###14   David Alcalde
###150074 Iovannah Rudoy
###150553 Paloma Lever

 

## Agenda {.tabset .tabset-fade .tabset-pills}

+ Tema
+ Introducción
+ Datos
+ K-means
+ Dendograma
+ Preguntas
+ Conclusiones



###Tema

A nuestro equipo le fue asignado el siguiente tema (tema 2) en la clase del 4 de Diciembre del 2017

#### Agrupación

Cuentas con un set de datos que contiene información relacionada a la contaminación de Beijing -**PM2.5**- del 1 de enero de 2010 al 31 de diciembre del 2014. El set cuenta con las siguientes variables 

+ **No:** row number
+ **year:** year of data in this row
+ **month:** month of data in this row
+ **day:** day of data in this row 
+ **hour:** hour of data in this row
+ **pm2.5:** PM2.5 concentration ($ug/m^3$)
+ **DEWP:** Dew Point, it's a more accurate way of measuring the humidity and comfort of air,
+ **TEMP:** Temperature
+ **PRES:** Pressure (hPa)
+ **cbwd:** Combined wind direction
+ **lws:** Cumulated wind speed (m/s)
+ **ls:** Cumulated hours or snow
+ **lr:** Cumulated hours of rain

Lo que tienes que hacer: 

+ Elimina del set las variables: `No`, `year`, `month`, `day`
+ Genera un k-means ocupando el resto de las variables
+ Genera un dendograma con el resto de las variables


###Introducción 

La contaminaci?n en el medio ambiente es una consecuencia inmediata de la industrializaci?n y la tecnificaci?n de la vida, a lo largo de los a?os ha dejado una capa cada vez m?s densa en las ciudades m?s pobladas del mundo y se ha convertido en una amenaza para la salud p?blica y no se han hecho los suficientes cambios en la industria para poder combatir exitosamente este fen?meno.
Una investigaci?n del Colegio del Medio Ambiente de la Universidad de Nanjing relacion? la contaminaci?n con casi un tercio de todas las muertes que se producen en China, ubicando a la poluci?n en el mismo nivel que fumar tabaco como amenaza para la salud p?blica

Teniendo un set de datos que contiene informaci?n relevante respecto al nivel de contaminaci?n de la ciudad de Behin en 5 a?os, el objetivo es lograr su agrupaci?n mediante el uso de dos m?todos no supervisados de agrpaci?n que son k-means clustering y dendogramas para as? poder centrar nuestro an?lisis de estos en grupos que compartan ciertas caracter?sticas entre s? y conocer qu? es lo que los diiferencia


###Datos

```{r echo = FALSE, warning = FALSE, message=FALSE}
library(readr)
library(tidyverse)
library(ggplot2)
library(plotly)
library(stringr)
library(dplyr)
library(class) 
library(C50)
library(ROCR)
library(caret) 
library(knitr) 
library(tidyr)
library(rpart)
library(MLmetrics)
library(lubridate)
library(ggdendro)
library(stringr)
setwd(".")
```

```{r warning=FALSE}
set.seed(14)
#Iovannah
data <- read_csv('~/Desktop/Mineria_de_datos/pollution.csv')

#Paloma
#data <- read_csv("../data/pollution.csv")
summary(data)

#Eliminamos 2000 valores vacíos que tenía la base de datos para la variable pw2.5
data <- na.omit(data)
#Sin numero ni dia
data<- data[,-c(1,4)]
data$year <- factor(data$year)
data$month <- factor(data$month)
variables <- names(data)
rows <- dim(data)[1]

clases <- sapply(data, function(x) class(x))
```

El numero total de observaciones en el dataset es `r rows`

Como podemos observar del primer resumen, pm2.5 es la variable con m?s NA's. De un set que cuenta con `r rows` observaciones, 2067 son NA's en pm2.5, ese es el `r (2067/rows * 100)`% de los datos, que es muy chico, por lo que para nuestro an?lisis futuro vamos a quitarlo utilizando el comando na.omit().

```{r echo = FALSE, warning = FALSE, message=FALSE}
#variables categoricas y numericas
categoricas <- data[,which(clases %in% c("character", "factor"))]
numericas <- data[,-which(clases %in% c("character", "factor"))]

#cardinalidad
uniques_num <- sapply(numericas, function(x) unique(x) %>% length())
uniques_num <- as.data.frame(uniques_num)

uniques_cat <- sapply(categoricas, function(x) unique(x) %>% length())
uniques_cat <- as.data.frame(uniques_cat)

#valores unicos

valores_unicos_num <- sapply(numericas, function(x) unique(x))
hvalores_unicos_cat <- sapply(categoricas, function(x) unique(x))

#uniqueness

porcentaje_unicos_num <-  round(uniques_num/(nrow(data)-1) * 100, 2)
porcentaje_unicos_num <- as.data.frame(porcentaje_unicos_num)

porcentaje_unicos_cat <- round(uniques_cat/(nrow(data)-1) * 100, 2)
porcentaje_unicos_cat$lk <- as.data.frame(porcentaje_unicos_cat)

#vacíos

nan_num <- sapply(numericas, function(x) sum(is.na(x)))
nan_num <- as.data.frame(nan_num)

nan_cat <- sapply(categoricas, function(x) sum(is.na(x)))
nan_cat <- as.data.frame(nan_cat)

#Función de Moda
Moda <- function(x){
  if (class(x) %in% c("character", "factor")) {
    table(x) %>%
      which.max() %>%
      names()
  }
  else {
    table(round(x, 2)) %>%
      which.max() %>%
      names()
  }
}

#moda
moda_num <- sapply(numericas, function(x) Moda(x))
moda_num <- as.data.frame(moda_num)

moda_cat <- sapply(categoricas, function(x) Moda(x))
moda_cat <- as.data.frame(moda_cat)

#Mínimo
minimo <- sapply(numericas, function(x) min(x))
minimo <- as.data.frame(minimo)

#Máximo
maximo <- sapply(numericas, function(x) max(x))
maximo <- as.data.frame(maximo)

#Promedio
promedio <- sapply(numericas, function(x) mean(x))
promedio <- as.data.frame(promedio)

#Mediana
mediana <- sapply(numericas, function(x) median(x))
mediana <- as.data.frame(mediana)

#Primer cuartil
primer_cuartil <- sapply(numericas, function(x) quantile(x)[2]) 
primer_cuartil <- as.data.frame(primer_cuartil)

#Tercer cuartil
tercer_cuartil <- sapply(numericas, function(x) quantile(x)[4]) 
tercer_cuartil <- as.data.frame(tercer_cuartil)

#Desviación estándar
desvest <- sapply(numericas, function(x) sd(x))
desvest <- as.data.frame(desvest)

#Tabla de data profiling
df_categoric <- cbind(uniques_cat, nan_cat, moda_cat)
names(df_categoric) <- str_replace_all(names(df_categoric), "_cat", "")

df_numeric <- cbind(uniques_num, nan_num, minimo, maximo, promedio, desvest,
                    mediana, moda_num, primer_cuartil, tercer_cuartil) 
names(df_numeric) <- str_replace_all(names(df_numeric), "_num", "")

```

**Estadística general, Data Profiling*
```{r echo=F, warning=FALSE, error=FALSE, message=FALSE}
kable(df_numeric, format.args = list(big.mark=",", scientific=F))
```

Podemos decir del PM2.5 que es una variable numérica que va del 0 al 994, con una desviación estándar de 92. Además, la media de esta variable es 98, lo que significa que los números mayores a 200 deberían ser alarmantes que estan contenidos en menos del 25% de los datos. 
La temperatura en Beijing var?a mucho a lo largo del a?o y en las distintas regions, va de  -19C a 42C.
DEWP es el grado de humedad, normalmente va de 10 a 26 grados y cualquier valor arriba o abajo puede causar un gran disomfort para el ser humano ya que menor a 10?C incluso menor a 0?C puede ser demasaido seco o mayor a 30?C puede ser asfixiante. En Beijing vemos que va de -40? a 28? lo cual est? relacionado con las teperaturas extremas a la sque llega a alcanzar.


```{r echo=F, warning=FALSE, error=FALSE, message=FALSE}

kable(df_categoric, format.args = list(big.mark=",", scientific=F))
``` 

Tenemos 5 años, con una moda del 2013, 12 meses con una moda en Julio y 4 valores para cbwd con una moda de SE (South East).

Preparamos los datos
```{r echo = FALSE, warning = FALSE, message = FALSE}
#data$cbwd <- as.factor(as.numeric(data$cbwd))
data_previo <- data
data <- data[,-c(1,2,8)] #Quitamos year, month, cbwd
data1 <- data
data1 %>%
  gather(-pm2.5, key = "some_var_name", value = "numeric_values") %>%
  ggplot(aes(x =  numeric_values, y =  pm2.5)) +
    geom_point() +
    facet_wrap(~ some_var_name, scales = "free")
```

Al ver los datos podemos observar que la hora no es un dato constante.
```{r echo = FALSE, warning = FALSE, message = FALSE}
data_scale <- scale(data) %>% as.data.frame()
summary(data_scale)
```

###K-means
Las variables que màs nos interesan para aplicar el algoritmo son las numericas por lo que quitamos CBWD, año y mes.

¿Cuántos grupos generaste? 
Para decidir el numero de grupos, hacemos el metodo del codo generando hasta 10 clusters. 
```{r echo = TRUE, warning=FALSE, message=FALSE}
retail_scaled <- data_scale

k_2  <- kmeans(retail_scaled, centers=2, iter.max=10)
k_3  <- kmeans(retail_scaled, centers=3, iter.max=10)
k_4  <- kmeans(retail_scaled, centers=4, iter.max=10)
k_5  <- kmeans(retail_scaled, centers=5, iter.max=10)
k_6  <- kmeans(retail_scaled, centers=6, iter.max=10)
k_7  <- kmeans(retail_scaled, centers=7, iter.max=10)
k_8  <- kmeans(retail_scaled, centers=8, iter.max=10)
k_9  <- kmeans(retail_scaled, centers=9, iter.max=10)
k_10 <- kmeans(retail_scaled, centers=10, iter.max=10)

tot_sumsquares <- k_2$totss

elbow_data <- data.frame(clusters = c(2,3,4,5,6,7,8,9,10),
                         sum_squares =c(k_2$tot.withinss/tot_sumsquares,
                                        k_3$tot.withinss/tot_sumsquares,
                                        k_4$tot.withinss/tot_sumsquares,
                                        k_5$tot.withinss/tot_sumsquares,
                                        k_6$tot.withinss/tot_sumsquares,
                                        k_7$tot.withinss/tot_sumsquares,
                                        k_8$tot.withinss/tot_sumsquares,
                                        k_9$tot.withinss/tot_sumsquares,
                                        k_10$tot.withinss/tot_sumsquares
                                        ))

ggplot(elbow_data, aes(x=clusters, y=sum_squares)) +
  geom_point() +
  geom_line() +
  theme_bw()
```

Con el metodo del codo vemos que el punto optimo es tener 7 clusters ya que si elijieramos 6 veriamos que aun sigue bajando la suma de cuadrados y con 8 y 9 la diferencia que hay es menor a 0.1.

```{r}
table(k_7$cluster)
```

Podemos observar las coordenadas de cada centro: 
```{r}
k_7$centers
```

```{r}
centroides <- as.data.frame(k_7$centers)
centroides$center <- "Y"
centroides$cluster <- "centroide"

data_clustered <- data_scale
data_clustered$cluster <- k_7$cluster
data_clustered$center <- "N"
data_clustered_centroides <- rbind(data_clustered,centroides)



ggplot(data_clustered_centroides, aes(x=data_clustered_centroides$DEWP, y=data_clustered_centroides$pm2.5,
                                    color= as.factor(cluster), shape=center)) + geom_point() + scale_color_brewer(palette="Spectral",name="Cluster")+ theme_bw()

ggplot(data_clustered_centroides, aes(x=data_clustered_centroides$hour, y=data_clustered_centroides$pm2.5,
                                    color= as.factor(cluster), shape=center)) + geom_point() + scale_color_brewer(palette="Spectral",name="Cluster")+ theme_bw()


ggplot(data_clustered_centroides, aes(x=data_clustered_centroides$TEMP, y=data_clustered_centroides$pm2.5,
                                    color= as.factor(cluster), shape=center)) + geom_point() + scale_color_brewer(palette="Spectral",name="Cluster")+ theme_bw()


ggplot(data_clustered_centroides, aes(x=data_clustered_centroides$PRES, y=data_clustered_centroides$pm2.5,
                                    color= as.factor(cluster), shape=center)) + geom_point() + scale_color_brewer(palette="Spectral",name="Cluster")+ theme_bw()

ggplot(data_clustered_centroides, aes(x=data_clustered_centroides$Iws, y=data_clustered_centroides$pm2.5,
                                    color= as.factor(cluster), shape=center)) + geom_point() + scale_color_brewer(palette="Spectral",name="Cluster")+ theme_bw()

ggplot(data_clustered_centroides, aes(x=data_clustered_centroides$Is, y=data_clustered_centroides$pm2.5,
                                    color= as.factor(cluster), shape=center)) + geom_point() + scale_color_brewer(palette="Spectral",name="Cluster")+ theme_bw()

ggplot(data_clustered_centroides, aes(x=data_clustered_centroides$Ir, y=data_clustered_centroides$pm2.5,
                                    color= as.factor(cluster), shape=center)) + geom_point() + scale_color_brewer(palette="Spectral",name="Cluster")+ theme_bw()





```

####Data Profiling

```{r echo = TRUE, warning=FALSE, message=FALSE}

data <- cbind(data_previo,data_clustered$cluster)

```

```{r}
names(data) <- c("year", "month" ,"hour", "pm2.5", "DEWP", "TEMP", "PRES","cbwd" ,"Iws", "Is", "Ir", "cluster")
data$pm2.5 <- as.numeric(data$pm2.5)
cluster1 <- filter(data,data$cluster == 1)
cluster2 <- filter(data,data$cluster == 2)
cluster3 <- filter(data,data$cluster == 3)
cluster4 <- filter(data,data$cluster == 4)
cluster5 <- filter(data,data$cluster == 5)
cluster6 <- filter(data,data$cluster == 6)
cluster7 <- filter(data,data$cluster == 7)

```

Cluster 1

```{r echo = FALSE, warning = FALSE, message=FALSE}
cluster1$pm2.5 <- as.numeric(cluster1$pm2.5)

#variables categoricas y numericas
categoricas <- cluster1[,which(clases %in% c("character", "factor"))]
numericas <- cluster1[,-which(clases %in% c("character", "factor"))]

#cardinalidad
uniques_num <- sapply(numericas, function(x) unique(x) %>% length())
uniques_num <- as.data.frame(uniques_num)

uniques_cat <- sapply(categoricas, function(x) unique(x) %>% length())
uniques_cat <- as.data.frame(uniques_cat)

#valores unicos

valores_unicos_num <- sapply(numericas, function(x) unique(x))
hvalores_unicos_cat <- sapply(categoricas, function(x) unique(x))

#uniqueness

porcentaje_unicos_num <-  round(uniques_num/(nrow(cluster1)-1) * 100, 2)
porcentaje_unicos_num <- as.data.frame(porcentaje_unicos_num)

porcentaje_unicos_cat <- round(uniques_cat/(nrow(cluster1)-1) * 100, 2)
porcentaje_unicos_cat$lk <- as.data.frame(porcentaje_unicos_cat)

#vacíos

nan_num <- sapply(numericas, function(x) sum(is.na(x)))
nan_num <- as.data.frame(nan_num)

nan_cat <- sapply(categoricas, function(x) sum(is.na(x)))
nan_cat <- as.data.frame(nan_cat)

#moda
moda_num <- sapply(numericas, function(x) Moda(x))
moda_num <- as.data.frame(moda_num)

moda_cat <- sapply(categoricas, function(x) Moda(x))
moda_cat <- as.data.frame(moda_cat)

#Mínimo
minimo <- sapply(numericas, function(x) min(x))
minimo <- as.data.frame(minimo)

#Máximo
maximo <- sapply(numericas, function(x) max(x))
maximo <- as.data.frame(maximo)

#Promedio
promedio <- sapply(numericas, function(x) mean(x))
promedio <- as.data.frame(promedio)

#Mediana
mediana <- sapply(numericas, function(x) median(x))
mediana <- as.data.frame(mediana)

#Primer cuartil
primer_cuartil <- sapply(numericas, function(x) quantile(x)[2]) 
primer_cuartil <- as.data.frame(primer_cuartil)

#Tercer cuartil
tercer_cuartil <- sapply(numericas, function(x) quantile(x)[4]) 
tercer_cuartil <- as.data.frame(tercer_cuartil)

#Desviación estándar
desvest <- sapply(numericas, function(x) sd(x))
desvest <- as.data.frame(desvest)

#Tabla de data profiling
df_categoric <- cbind(uniques_cat, nan_cat, moda_cat)
names(df_categoric) <- str_replace_all(names(df_categoric), "_cat", "")

df_numeric <- cbind(uniques_num, nan_num, minimo, maximo, promedio, desvest,
                    mediana, moda_num, primer_cuartil, tercer_cuartil) 
names(df_numeric) <- str_replace_all(names(df_numeric), "_num", "")

kable(df_numeric, format.args = list(big.mark=",", scientific=F))
kable(df_categoric, format.args = list(big.mark=",", scientific = F))
```

Cluster 1: "Final del 2013 con contaminación *medio alta*"
Año: la mayoría de los datos son del 2013
Mes: la mayoría son de Octubre (mes 10)
cbwd: la mayoría son datos que van a cv

hora: la más común es a las 11 pm, 
pm2.5: va de 140 a 994, con una moda de 227 y el 75% de los datos son menores a 343. (Son datos promedio)
DEWP: va de -25 a 27, con una moda de 5 y el 75% de los datos es menor a 4. Esto significa que la humedad va a los dos extremos. Pero en general es seco.
TEMP: va de -16 a 30, con una moda de -3 y el 75% son menores a 11. (Temperaturas bajas, pero no afectan la humedad)
PRES: va de 997 a 1037, con una moda de 1021 y poca desviación. 
Iws: va de 0.45 a 111.78, con una moda de 0.89 y el 75% es menor a 5. Por lo que hay poco viento (velocidad del viento).
Is: va de 0 a 5, con una moda de 0. Por lo que normalmente no hay nieve.
Ir: va de 0 a 6, con una moda de 0. Esto significa que casi no hay lluvia y como la lluvia disminuye la contaminación, se entiende que más del 75% de los datos tienen un pm2.5 mayor a 230.




Cluster 2

```{r echo = FALSE, warning = FALSE, message=FALSE}

#variables categoricas y numericas
categoricas <- cluster2[,which(clases %in% c("character", "factor"))]
numericas <- cluster2[,-which(clases %in% c("character", "factor"))]

#cardinalidad
uniques_num <- sapply(numericas, function(x) unique(x) %>% length())
uniques_num <- as.data.frame(uniques_num)

uniques_cat <- sapply(categoricas, function(x) unique(x) %>% length())
uniques_cat <- as.data.frame(uniques_cat)

#valores unicos

valores_unicos_num <- sapply(numericas, function(x) unique(x))
hvalores_unicos_cat <- sapply(categoricas, function(x) unique(x))

#uniqueness

porcentaje_unicos_num <-  round(uniques_num/(nrow(cluster2)-1) * 100, 2)
porcentaje_unicos_num <- as.data.frame(porcentaje_unicos_num)

porcentaje_unicos_cat <- round(uniques_cat/(nrow(cluster2)-1) * 100, 2)
porcentaje_unicos_cat$lk <- as.data.frame(porcentaje_unicos_cat)

#vacíos

nan_num <- sapply(numericas, function(x) sum(is.na(x)))
nan_num <- as.data.frame(nan_num)

nan_cat <- sapply(categoricas, function(x) sum(is.na(x)))
nan_cat <- as.data.frame(nan_cat)

#moda
moda_num <- sapply(numericas, function(x) Moda(x))
moda_num <- as.data.frame(moda_num)

moda_cat <- sapply(categoricas, function(x) Moda(x))
moda_cat <- as.data.frame(moda_cat)

#Mínimo
minimo <- sapply(numericas, function(x) min(x))
minimo <- as.data.frame(minimo)

#Máximo
maximo <- sapply(numericas, function(x) max(x))
maximo <- as.data.frame(maximo)

#Promedio
promedio <- sapply(numericas, function(x) mean(x))
promedio <- as.data.frame(promedio)

#Mediana
mediana <- sapply(numericas, function(x) median(x))
mediana <- as.data.frame(mediana)

#Primer cuartil
primer_cuartil <- sapply(numericas, function(x) quantile(x)[2]) 
primer_cuartil <- as.data.frame(primer_cuartil)

#Tercer cuartil
tercer_cuartil <- sapply(numericas, function(x) quantile(x)[4]) 
tercer_cuartil <- as.data.frame(tercer_cuartil)

#Desviación estándar
desvest <- sapply(numericas, function(x) sd(x))
desvest <- as.data.frame(desvest)

#Tabla de data profiling
df_categoric <- cbind(uniques_cat, nan_cat, moda_cat)
names(df_categoric) <- str_replace_all(names(df_categoric), "_cat", "")

df_numeric <- cbind(uniques_num, nan_num, minimo, maximo, promedio, desvest,
                    mediana, moda_num, primer_cuartil, tercer_cuartil) 
names(df_numeric) <- str_replace_all(names(df_numeric), "_num", "")

kable(df_numeric, format.args = list(big.mark=",", scientific=F))
kable(df_categoric, format.args = list(big.mark=",", scientific = F))
```


Cluster 2: "Invierno con contaminación *normal*"
Año: la mayoría son datos del 2012
Mes: la mayoría son datos de Febrero (mes 2), nota: unicamente hay 4 meses en este cluster
cbwd: moda SE.

hora: la moda es de 11 am, el 75% son datos antes de las 15:00.
pm2.5: va de 21 a 453, con una moda de 68 y el 75% de los datos son menores a 133. Esto implica relativamente poca contaminación.
DEWP: va de -11 a 1, con una moda de -6 y el 75% de los datos son menores a -3. Esto significa que es un clima seco, pero no es extremo.
TEMP: va de -10 a 1, con una moda de -2 y el 75% de los datos son menores a -2. Esto es entendible por el mes (Febrero en general), además es entendible que la contaminación no sea muy alta, pues en general temperturas bajas implican menos contaminación.
PRES: va de 1017 a 1041, con una moda de 1020 y continúa habiendo poca varianza.
Iws: va de 0.45 a 127.84, con una moda de 0.89 y el 75% de los datos tiene valores menores a 66.63. Esto significa que la velocidad del aire es "media", puede contribuir a que la contaminación no sea tan elevada. Ya que en este cluster tiende a no ser mayor al nivel peligroso (pm2.5 = 220).
Is: va de 6 a 27 horas acumuladas de nieve, (se entiende por ser febrero).
Ir: no hay horas de lluvia (esto se entiende porque hay nieve, lo que sustituye a la lluvia)


Cluster 3

```{r echo = FALSE, warning = FALSE, message=FALSE}

#variables categoricas y numericas
categoricas <- cluster3[,which(clases %in% c("character", "factor"))]
numericas <- cluster3[,-which(clases %in% c("character", "factor"))]

#cardinalidad
uniques_num <- sapply(numericas, function(x) unique(x) %>% length())
uniques_num <- as.data.frame(uniques_num)

uniques_cat <- sapply(categoricas, function(x) unique(x) %>% length())
uniques_cat <- as.data.frame(uniques_cat)

#valores unicos

valores_unicos_num <- sapply(numericas, function(x) unique(x))
hvalores_unicos_cat <- sapply(categoricas, function(x) unique(x))

#uniqueness

porcentaje_unicos_num <-  round(uniques_num/(nrow(cluster3)-1) * 100, 2)
porcentaje_unicos_num <- as.data.frame(porcentaje_unicos_num)

porcentaje_unicos_cat <- round(uniques_cat/(nrow(cluster3)-1) * 100, 2)
porcentaje_unicos_cat$lk <- as.data.frame(porcentaje_unicos_cat)

#vacíos

nan_num <- sapply(numericas, function(x) sum(is.na(x)))
nan_num <- as.data.frame(nan_num)

nan_cat <- sapply(categoricas, function(x) sum(is.na(x)))
nan_cat <- as.data.frame(nan_cat)

#moda
moda_num <- sapply(numericas, function(x) Moda(x))
moda_num <- as.data.frame(moda_num)

moda_cat <- sapply(categoricas, function(x) Moda(x))
moda_cat <- as.data.frame(moda_cat)

#Mínimo
minimo <- sapply(numericas, function(x) min(x))
minimo <- as.data.frame(minimo)

#Máximo
maximo <- sapply(numericas, function(x) max(x))
maximo <- as.data.frame(maximo)

#Promedio
promedio <- sapply(numericas, function(x) mean(x))
promedio <- as.data.frame(promedio)

#Mediana
mediana <- sapply(numericas, function(x) median(x))
mediana <- as.data.frame(mediana)

#Primer cuartil
primer_cuartil <- sapply(numericas, function(x) quantile(x)[2]) 
primer_cuartil <- as.data.frame(primer_cuartil)

#Tercer cuartil
tercer_cuartil <- sapply(numericas, function(x) quantile(x)[4]) 
tercer_cuartil <- as.data.frame(tercer_cuartil)

#Desviación estándar
desvest <- sapply(numericas, function(x) sd(x))
desvest <- as.data.frame(desvest)

#Tabla de data profiling
df_categoric <- cbind(uniques_cat, nan_cat, moda_cat)
names(df_categoric) <- str_replace_all(names(df_categoric), "_cat", "")

df_numeric <- cbind(uniques_num, nan_num, minimo, maximo, promedio, desvest,
                    mediana, moda_num, primer_cuartil, tercer_cuartil) 
names(df_numeric) <- str_replace_all(names(df_numeric), "_num", "")

kable(df_numeric, format.args = list(big.mark=",", scientific=F))
kable(df_categoric, format.args = list(big.mark=",", scientific = F))
```


Cluster 3: "Madrugada con relativamente poca contaminación y calor"
Año: la moda es del 2014
Mes: 7 (verano), 10 meses
cbwd: moda SE

hora: la moda es 00:00, y el 75% están antes de las 08:00 am.
pm2.5: va de 1 a 361, con una moda de 77 y el 75% son menores a 132 (relativamente poca contaminación, pocos elementos arriba del pm 2.5 considerado peligroso)
DEWP: va de -14 a 28, con una moda de 18 y el 75% se encuentran antes del 20. Relativamente humedo.
TEMP: va de 1 a 32, con moda 23 y el 75% antes de 23. El 50% entre 16 y 23. Esto es entendible por la época del año, calor medio.
PRES: va de 994 a 1029, es un poco menor a los otros clusters. Sigue habiendo poca varianza.
Iws: va de 0.45 a 208.79, con moda de 0.89 y el 75% menores a 9.84. Esto implica que hubo viento, pero no de muy altas velocidades.
Is: No hubo nieve.
Ir: el 75% de los datos no tuvieron horas de lluvia, pero se registraron hasta 36 horas seguidas de lluvia en algunas observaciones. 


Cluster 4

```{r echo = FALSE, warning = FALSE, message=FALSE}

#variables categoricas y numericas
categoricas <- cluster4[,which(clases %in% c("character", "factor"))]
numericas <- cluster4[,-which(clases %in% c("character", "factor"))]

#cardinalidad
uniques_num <- sapply(numericas, function(x) unique(x) %>% length())
uniques_num <- as.data.frame(uniques_num)

uniques_cat <- sapply(categoricas, function(x) unique(x) %>% length())
uniques_cat <- as.data.frame(uniques_cat)

#valores unicos

valores_unicos_num <- sapply(numericas, function(x) unique(x))
hvalores_unicos_cat <- sapply(categoricas, function(x) unique(x))

#uniqueness

porcentaje_unicos_num <-  round(uniques_num/(nrow(cluster4)-1) * 100, 2)
porcentaje_unicos_num <- as.data.frame(porcentaje_unicos_num)

porcentaje_unicos_cat <- round(uniques_cat/(nrow(cluster4)-1) * 100, 2)
porcentaje_unicos_cat$lk <- as.data.frame(porcentaje_unicos_cat)

#vacíos

nan_num <- sapply(numericas, function(x) sum(is.na(x)))
nan_num <- as.data.frame(nan_num)

nan_cat <- sapply(categoricas, function(x) sum(is.na(x)))
nan_cat <- as.data.frame(nan_cat)

#moda
moda_num <- sapply(numericas, function(x) Moda(x))
moda_num <- as.data.frame(moda_num)

moda_cat <- sapply(categoricas, function(x) Moda(x))
moda_cat <- as.data.frame(moda_cat)

#Mínimo
minimo <- sapply(numericas, function(x) min(x))
minimo <- as.data.frame(minimo)

#Máximo
maximo <- sapply(numericas, function(x) max(x))
maximo <- as.data.frame(maximo)

#Promedio
promedio <- sapply(numericas, function(x) mean(x))
promedio <- as.data.frame(promedio)

#Mediana
mediana <- sapply(numericas, function(x) median(x))
mediana <- as.data.frame(mediana)

#Primer cuartil
primer_cuartil <- sapply(numericas, function(x) quantile(x)[2]) 
primer_cuartil <- as.data.frame(primer_cuartil)

#Tercer cuartil
tercer_cuartil <- sapply(numericas, function(x) quantile(x)[4]) 
tercer_cuartil <- as.data.frame(tercer_cuartil)

#Desviación estándar
desvest <- sapply(numericas, function(x) sd(x))
desvest <- as.data.frame(desvest)

#Tabla de data profiling
df_categoric <- cbind(uniques_cat, nan_cat, moda_cat)
names(df_categoric) <- str_replace_all(names(df_categoric), "_cat", "")

df_numeric <- cbind(uniques_num, nan_num, minimo, maximo, promedio, desvest,
                    mediana, moda_num, primer_cuartil, tercer_cuartil) 
names(df_numeric) <- str_replace_all(names(df_numeric), "_num", "")

kable(df_numeric, format.args = list(big.mark=",", scientific=F))
kable(df_categoric, format.args = list(big.mark=",", scientific = F))
```

Cluster 4: "Mucho calor, mucho viento y relativamente poca contaminación en la tarde (verano)"
Año: moda 2014
Mes: moda 7 (verano), con 9 meses 
cbwd: SE

hora: va de 14:00 a 20:00, con una moda de 17:00. Por lo que son datos en la tarde.
pm2.5: va de 1 a 399, el 75% son menores a 121, moda de 16. Por lo que hay poca contaminación en general. 
DEWP: va de -18 a 28, alto grado de humedad con moda 17. Humedo.
TEMP: va de 4 a 42, con una moda de 27. Por lo que son meses de mucho calor, cluster de más calor.1 
PRES: va de 991 a 1024, moda de 1006, por lo que continúa habiendo poca varianza. 
Iws: va de 0.45 a 171, con el 75% de los datos menores a 22.8. Sí hubo viento, incluso a veces a velocidades muy altas. Esto podría reducir la contaminación.
Is: no hubo horas de nieve (se entiende por la temperatura)
Ir: el 75% de los datos no tuvieron lluvia, pero va de 0 a 8horas de lluvia.

Cluster 5

```{r echo = FALSE, warning = FALSE, message=FALSE}

#variables categoricas y numericas
categoricas <- cluster5[,which(clases %in% c("character", "factor"))]
numericas <- cluster5[,-which(clases %in% c("character", "factor"))]

#cardinalidad
uniques_num <- sapply(numericas, function(x) unique(x) %>% length())
uniques_num <- as.data.frame(uniques_num)

uniques_cat <- sapply(categoricas, function(x) unique(x) %>% length())
uniques_cat <- as.data.frame(uniques_cat)

#valores unicos

valores_unicos_num <- sapply(numericas, function(x) unique(x))
hvalores_unicos_cat <- sapply(categoricas, function(x) unique(x))

#uniqueness

porcentaje_unicos_num <-  round(uniques_num/(nrow(cluster5)-1) * 100, 2)
porcentaje_unicos_num <- as.data.frame(porcentaje_unicos_num)

porcentaje_unicos_cat <- round(uniques_cat/(nrow(cluster5)-1) * 100, 2)
porcentaje_unicos_cat$lk <- as.data.frame(porcentaje_unicos_cat)

#vacíos

nan_num <- sapply(numericas, function(x) sum(is.na(x)))
nan_num <- as.data.frame(nan_num)

nan_cat <- sapply(categoricas, function(x) sum(is.na(x)))
nan_cat <- as.data.frame(nan_cat)

#moda
moda_num <- sapply(numericas, function(x) Moda(x))
moda_num <- as.data.frame(moda_num)

moda_cat <- sapply(categoricas, function(x) Moda(x))
moda_cat <- as.data.frame(moda_cat)

#Mínimo
minimo <- sapply(numericas, function(x) min(x))
minimo <- as.data.frame(minimo)

#Máximo
maximo <- sapply(numericas, function(x) max(x))
maximo <- as.data.frame(maximo)

#Promedio
promedio <- sapply(numericas, function(x) mean(x))
promedio <- as.data.frame(promedio)

#Mediana
mediana <- sapply(numericas, function(x) median(x))
mediana <- as.data.frame(mediana)

#Primer cuartil
primer_cuartil <- sapply(numericas, function(x) quantile(x)[2]) 
primer_cuartil <- as.data.frame(primer_cuartil)

#Tercer cuartil
tercer_cuartil <- sapply(numericas, function(x) quantile(x)[4]) 
tercer_cuartil <- as.data.frame(tercer_cuartil)

#Desviación estándar
desvest <- sapply(numericas, function(x) sd(x))
desvest <- as.data.frame(desvest)

#Tabla de data profiling
df_categoric <- cbind(uniques_cat, nan_cat, moda_cat)
names(df_categoric) <- str_replace_all(names(df_categoric), "_cat", "")

df_numeric <- cbind(uniques_num, nan_num, minimo, maximo, promedio, desvest,
                    mediana, moda_num, primer_cuartil, tercer_cuartil) 
names(df_numeric) <- str_replace_all(names(df_numeric), "_num", "")

kable(df_numeric, format.args = list(big.mark=",", scientific=F))
kable(df_categoric, format.args = list(big.mark=",", scientific = F))
```


Cluster 5: "Principio de año, mucho viento, muy seco, en la tarde"
Año: 2013
Mes: 3 (9 meses registrados)
cbwd: NW

hora: 50% de los datos están entre 14:00 y 20:00hrs, por lo que son en la tarde-noche a inicios de año
pm2.5: va de 2 a 238, el 75% son menores a 90. Esto implica que hubo poca contaminación.
DEWP: va de -40 a 13. Esto implica un clima *muy* seco. El 75% de los datos es menor a -5.
TEMP: va de - 18 a 26, con el 75% menor a 11, y una moda de 2. Por lo que hay una gran varianza de temperatura, pero son temperaturas frías en general. Esto podría tener una relación con la baja contaminación.
PRES: va de 1005 a 1042, con una moda de 1025. Poca varianza. 
Iws: va de 0.45 a 132.76, con el 75% menor a 30.85. Esto implica que hubo bastante viento.
Is: en el 75% de los datos no hubo horas de nieve, pero se registraron hasta 5 horas de nieve. Puede relacionarse con la época del año (fin invierno-inicio primavera).
Ir: en el 75% de los datos no hubo horas de lluvia, pero se registraron hasta 10 horas de lluvia.


Cluster 6

```{r echo = FALSE, warning = FALSE, message=FALSE}

#variables categoricas y numericas
categoricas <- cluster6[,which(clases %in% c("character", "factor"))]
numericas <- cluster6[,-which(clases %in% c("character", "factor"))]

#cardinalidad
uniques_num <- sapply(numericas, function(x) unique(x) %>% length())
uniques_num <- as.data.frame(uniques_num)

uniques_cat <- sapply(categoricas, function(x) unique(x) %>% length())
uniques_cat <- as.data.frame(uniques_cat)

#valores unicos

valores_unicos_num <- sapply(numericas, function(x) unique(x))
hvalores_unicos_cat <- sapply(categoricas, function(x) unique(x))

#uniqueness

porcentaje_unicos_num <-  round(uniques_num/(nrow(cluster6)-1) * 100, 2)
porcentaje_unicos_num <- as.data.frame(porcentaje_unicos_num)

porcentaje_unicos_cat <- round(uniques_cat/(nrow(cluster6)-1) * 100, 2)
porcentaje_unicos_cat$lk <- as.data.frame(porcentaje_unicos_cat)

#vacíos

nan_num <- sapply(numericas, function(x) sum(is.na(x)))
nan_num <- as.data.frame(nan_num)

nan_cat <- sapply(categoricas, function(x) sum(is.na(x)))
nan_cat <- as.data.frame(nan_cat)

#moda
moda_num <- sapply(numericas, function(x) Moda(x))
moda_num <- as.data.frame(moda_num)

moda_cat <- sapply(categoricas, function(x) Moda(x))
moda_cat <- as.data.frame(moda_cat)

#Mínimo
minimo <- sapply(numericas, function(x) min(x))
minimo <- as.data.frame(minimo)

#Máximo
maximo <- sapply(numericas, function(x) max(x))
maximo <- as.data.frame(maximo)

#Promedio
promedio <- sapply(numericas, function(x) mean(x))
promedio <- as.data.frame(promedio)

#Mediana
mediana <- sapply(numericas, function(x) median(x))
mediana <- as.data.frame(mediana)

#Primer cuartil
primer_cuartil <- sapply(numericas, function(x) quantile(x)[2]) 
primer_cuartil <- as.data.frame(primer_cuartil)

#Tercer cuartil
tercer_cuartil <- sapply(numericas, function(x) quantile(x)[4]) 
tercer_cuartil <- as.data.frame(tercer_cuartil)

#Desviación estándar
desvest <- sapply(numericas, function(x) sd(x))
desvest <- as.data.frame(desvest)

#Tabla de data profiling
df_categoric <- cbind(uniques_cat, nan_cat, moda_cat)
names(df_categoric) <- str_replace_all(names(df_categoric), "_cat", "")

df_numeric <- cbind(uniques_num, nan_num, minimo, maximo, promedio, desvest,
                    mediana, moda_num, primer_cuartil, tercer_cuartil) 
names(df_numeric) <- str_replace_all(names(df_numeric), "_num", "")

kable(df_numeric, format.args = list(big.mark=",", scientific=F))
kable(df_categoric, format.args = list(big.mark=",", scientific = F))
```

Cluster 6: "Inicio de año en la madrugada, muy frío y muy seco contaminación media-baja"
Año: 2010
Mes: 1 (inicios de año)
cbwd: NW

hora: 50% de los datos están entre 3:00 y 8:00hrs. (madrugada)
pm2.5: va de 2 a 275, el 75% son menores a 106. Poca contaminación, pero más alta que algunos otros.
DEWP: va de -35 a 9. Moda de -10 y el 75% de los datos es menor a -5. (muy seco)
TEMP: va de - 18 a 18, con el 75% menor a 3, y una moda de -3. (*Muy* frío, se entiende por la época del año).
PRES: va de 1007 a 1046, con una moda de 1027. Poca varianza. 
Iws: va de 0.45 a 127.83, con el 75% menor a 18.77.  (Poco viento)
Is: en el 75% de los datos no hubo horas de nieve, pero se registraron hasta 5 horas de nieve. 
Ir: en el 75% de los datos no hubo horas de lluvia, pero se registraron hasta 6 horas de lluvia.


Cluster 7

```{r echo = FALSE, warning = FALSE, message=FALSE}

#variables categoricas y numericas
categoricas <- cluster7[,which(clases %in% c("character", "factor"))]
numericas <- cluster7[,-which(clases %in% c("character", "factor"))]

#cardinalidad
uniques_num <- sapply(numericas, function(x) unique(x) %>% length())
uniques_num <- as.data.frame(uniques_num)

uniques_cat <- sapply(categoricas, function(x) unique(x) %>% length())
uniques_cat <- as.data.frame(uniques_cat)

#valores unicos

valores_unicos_num <- sapply(numericas, function(x) unique(x))
hvalores_unicos_cat <- sapply(categoricas, function(x) unique(x))

#uniqueness

porcentaje_unicos_num <-  round(uniques_num/(nrow(cluster7)-1) * 100, 2)
porcentaje_unicos_num <- as.data.frame(porcentaje_unicos_num)

porcentaje_unicos_cat <- round(uniques_cat/(nrow(cluster7)-1) * 100, 2)
porcentaje_unicos_cat$lk <- as.data.frame(porcentaje_unicos_cat)

#vacíos

nan_num <- sapply(numericas, function(x) sum(is.na(x)))
nan_num <- as.data.frame(nan_num)

nan_cat <- sapply(categoricas, function(x) sum(is.na(x)))
nan_cat <- as.data.frame(nan_cat)

#moda
moda_num <- sapply(numericas, function(x) Moda(x))
moda_num <- as.data.frame(moda_num)

moda_cat <- sapply(categoricas, function(x) Moda(x))
moda_cat <- as.data.frame(moda_cat)

#Mínimo
minimo <- sapply(numericas, function(x) min(x))
minimo <- as.data.frame(minimo)

#Máximo
maximo <- sapply(numericas, function(x) max(x))
maximo <- as.data.frame(maximo)

#Promedio
promedio <- sapply(numericas, function(x) mean(x))
promedio <- as.data.frame(promedio)

#Mediana
mediana <- sapply(numericas, function(x) median(x))
mediana <- as.data.frame(mediana)

#Primer cuartil
primer_cuartil <- sapply(numericas, function(x) quantile(x)[2]) 
primer_cuartil <- as.data.frame(primer_cuartil)

#Tercer cuartil
tercer_cuartil <- sapply(numericas, function(x) quantile(x)[4]) 
tercer_cuartil <- as.data.frame(tercer_cuartil)

#Desviación estándar
desvest <- sapply(numericas, function(x) sd(x))
desvest <- as.data.frame(desvest)

#Tabla de data profiling
df_categoric <- cbind(uniques_cat, nan_cat, moda_cat)
names(df_categoric) <- str_replace_all(names(df_categoric), "_cat", "")

df_numeric <- cbind(uniques_num, nan_num, minimo, maximo, promedio, desvest,
                    mediana, moda_num, primer_cuartil, tercer_cuartil) 
names(df_numeric) <- str_replace_all(names(df_numeric), "_num", "")

kable(df_numeric, format.args = list(big.mark=",", scientific=F))
kable(df_categoric, format.args = list(big.mark=",", scientific = F))
```

Cluster 7: "MUCHISIMO VIENTO"
Año: moda 2010
Mes: diciembre, datos de los 11 meses
cbwd: NW

hora: 50% de los datos están entre 06:00 y 18:00hrs. (horas laborales)
pm2.5: va de 0 a 276, el 75% son menores a 21. Moda 11. (Poca contaminación)
DEWP: va de -38 a 13. Moda de -20. El 75% de los datos es menor a -11.  Esto implica un clima *muy* seco
TEMP: va de - 19 a 29, con el 75% menor a 8, y una moda de -1. Clima frío en general.
PRES: va de 1001 a 1046, con una moda de 1027. Poca varianza. 
Iws: va de 109 a 565.49, con el 75% mayor a 150. Esto implica que hay *mucho* viento, es el cluster con el más viento. 
Is: no hubo nieve (0)
Ir: en el 75% de los datos no hubo horas de lluvia, pero se registraron hasta 1 hora de lluvia.


###Dendograma
Nota: "Ocupa average linkeage"
```{r echo = TRUE, warning=FALSE, message=FALSE}
distance_matrix <- dist(data)
#dendogram_complete <- hclust(distance_matrix,method="complete")
#ggdendrogram(dendogram_complete, rotate=F, size =2)

```


###Preguntas

1. k-means

    + Cuántos grupos generaste, justificación 
    Generamos 7 grupos basados en la técnica "del codo", ya que al llegar a 7 grupos aún nos proporcionaba bastante información, pero el cambio de 7 a 8 aportaba muy poca.
    + Características de cada grupo *En la página anterior
    + Centroides obtenidos
```{r echo = FALSE}
k_7$centers
```
    + ¿Cuántos elementos hay por grupo? 

Cluster 1: `r nrow(cluster1)`

Cluster 2: `r nrow(cluster2)`

Cluster 3: `r nrow(cluster3)`

Cluster 4: `r nrow(cluster4)`

Cluster 5: `r nrow(cluster5)`

Cluster 6: `r nrow(cluster6)`

Cluster 7: `r nrow(cluster7)`
    
    + ¿Los grupos están balanceados? 
En general sí, pero no están bien balanceados. El cluster 2 tiene muy pocos datos, únicamente 161. Mientras que el mayor (cluster 4) tiene 10,570. En promedio tienen 5,964 observaciones.
    
    
2. Dendogramas

    + Ocupa *average-linkage*
    + De acuerdo al $k$ obtenido en la pregunta anterior genera el corte al dendograma y genera los grupos
    + ¿Cuántos elementos hay por grupo? 
    + ¿Los grupos están balanceados? 
    + Características de cada grupo
    
    
3. Diferencias entre las características de cada grupo


###Conclusiones

