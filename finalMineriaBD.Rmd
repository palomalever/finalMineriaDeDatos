---
title: "Examen_Final_DIP"
author: '150074'
date: "6/12/2017"
output: html_document
---

#Examen Final MinerÃ­a de Datos Agosto Diciembre 2017
###14   David Alcalde
###150074 Iovannah Rudoy
###150553 Paloma Lever

*** 

## Agenda {.tabset .tabset-fade .tabset-pills}

+ Tema
+ IntroducciÃ³n
+ Datos
+ K-means
+ Dendograma
+ Preguntas
+ Conclusiones

*** 

###Tema

A nuestro equipo le fue asignado el siguiente tema (tema 2) en la clase del 4 de Diciembre del 2017

#### AgrupaciÃ³n

Cuentas con un set de datos que contiene informaciÃ³n relacionada a la contaminaciÃ³n de Beijing -**PM2.5**- del 1 de enero de 2010 al 31 de diciembre del 2014. El set cuenta con las siguientes variables 

+ **No:** row number
+ **year:** year of data in this row
+ **month:** month of data in this row
+ **day:** day of data in this row 
+ **hour:** hour of data in this row
+ **pm2.5:** PM2.5 concentration ($ug/m^3$)
+ **DEWP:** Dew Point, it's a more accurate way of measuring the humidity and comfort of air,
+ **TEMP:** Temperature
+ **PRES:** Pressure (hPa)
+ **cbwd:** Combined wind direction
+ **lws:** Cumulated wind speed (m/s)
+ **ls:** Cumulated hours or snow
+ **lr:** Cumulated hours of rain

Lo que tienes que hacer: 

+ Elimina del set las variables: `No`, `year`, `month`, `day`
+ Genera un k-means ocupando el resto de las variables
+ Genera un dendograma con el resto de las variables


###IntroducciÃ³n 

La contaminación en el medio ambiente es una consecuencia inmediata de la industrialización y la tecnificación de la vida, a lo largo de los años ha dejado una capa cada vez más densa en las ciudades más pobladas del mundo y se ha convertido en una amenaza para la salud pública y no se han hecho los suficientes cambios en la industria para poder combatir exitosamente este fenómeno.
Una investigación del Colegio del Medio Ambiente de la Universidad de Nanjing relacionó la contaminación con casi un tercio de todas las muertes que se producen en China, ubicando a la polución en el mismo nivel que fumar tabaco como amenaza para la salud pública

Teniendo un set de datos que contiene información relevante respecto al nivel de contaminación de la ciudad de Behin en 5 años, el objetivo es lograr su agrupación mediante el uso de dos métodos no supervisados de agrpación que son k-means clustering y dendogramas para así poder centrar nuestro análisis de estos en grupos que compartan ciertas características entre sí y conocer qué es lo que los diiferencia


###Datos

```{r echo = FALSE, warning = FALSE, message=FALSE}
library(readr)
library(tidyverse)
library(ggplot2)
library(plotly)
library(stringr)
library(dplyr)
library(class) 
library(C50)
library(ROCR)
library(caret) 
library(knitr) 
library(tidyr)
library(rpart)
library(MLmetrics)
library(lubridate)
library(ggdendro)
library(stringr)
setwd(".")
```

```{r}
set.seed(14)
#Iovannah
#data <- read_csv('~/Desktop/Mineria_de_datos/pollution.csv')
#Paloma

data <- read_csv("../data/pollution.csv")
summary(data)

#Eliminamos 2000 valores vacÃ­os que tenÃ­a la base de datos para la variable pw2.5
data <- na.omit(data)
data <- data[,-c(1,4)]
data$year <- factor(data$year)
data$month <- factor(data$month)


variables <- names(data)
rows <- nrow(data)

clases <- sapply(data, function(x) class(x))
```

Como podemos observar del primer resumen, pm2.5 es la variable con más NA's. De un set que cuenta con `r rows` observaciones, 2067 son NA's en pm2.5, ese es el `r (2067/rows * 100)`% de los datos, que es muy chico, por lo que para nuestro análisis futuro vamos a quitarlo utilizando el comando na.omit().


```{r echo = FALSE, warning = FALSE, message=FALSE}
#variables categoricas y numericas
categoricas <- data[,which(clases %in% c("character", "factor"))]
numericas <- data[,-which(clases %in% c("character", "factor"))]

#cardinalidad
uniques_num <- sapply(numericas, function(x) unique(x) %>% length())
uniques_num <- as.data.frame(uniques_num)

uniques_cat <- sapply(categoricas, function(x) unique(x) %>% length())
uniques_cat <- as.data.frame(uniques_cat)

#valores unicos

valores_unicos_num <- sapply(numericas, function(x) unique(x))
hvalores_unicos_cat <- sapply(categoricas, function(x) unique(x))

#uniqueness

porcentaje_unicos_num <-  round(uniques_num/(nrow(data)-1) * 100, 2)
porcentaje_unicos_num <- as.data.frame(porcentaje_unicos_num)

porcentaje_unicos_cat <- round(uniques_cat/(nrow(data)-1) * 100, 2)
porcentaje_unicos_cat$lk <- as.data.frame(porcentaje_unicos_cat)

#vacÃ­os

nan_num <- sapply(numericas, function(x) sum(is.na(x)))
nan_num <- as.data.frame(nan_num)

nan_cat <- sapply(categoricas, function(x) sum(is.na(x)))
nan_cat <- as.data.frame(nan_cat)

#FunciÃ³n de Moda
Moda <- function(x){
  if (class(x) %in% c("character", "factor")) {
    table(x) %>%
      which.max() %>%
      names()
  }
  else {
    table(round(x, 2)) %>%
      which.max() %>%
      names()
  }
}

#moda
moda_num <- sapply(numericas, function(x) Moda(x))
moda_num <- as.data.frame(moda_num)

moda_cat <- sapply(categoricas, function(x) Moda(x))
moda_cat <- as.data.frame(moda_cat)

#MÃ­nimo
minimo <- sapply(numericas, function(x) min(x))
minimo <- as.data.frame(minimo)

#MÃ¡ximo
maximo <- sapply(numericas, function(x) max(x))
maximo <- as.data.frame(maximo)

#Promedio
promedio <- sapply(numericas, function(x) mean(x))
promedio <- as.data.frame(promedio)

#Mediana
mediana <- sapply(numericas, function(x) median(x))
mediana <- as.data.frame(mediana)

#Primer cuartil
primer_cuartil <- sapply(numericas, function(x) quantile(x)[2]) 
primer_cuartil <- as.data.frame(primer_cuartil)

#Tercer cuartil
tercer_cuartil <- sapply(numericas, function(x) quantile(x)[4]) 
tercer_cuartil <- as.data.frame(tercer_cuartil)

#DesviaciÃ³n estÃ¡ndar
desvest <- sapply(numericas, function(x) sd(x))
desvest <- as.data.frame(desvest)

#Tabla de data profiling
df_categoric <- cbind(uniques_cat, nan_cat, moda_cat)
names(df_categoric) <- str_replace_all(names(df_categoric), "_cat", "")

df_numeric <- cbind(uniques_num, nan_num, minimo, maximo, promedio, desvest,
                    mediana, moda_num, primer_cuartil, tercer_cuartil) 
names(df_numeric) <- str_replace_all(names(df_numeric), "_num", "")

```

**EstadÃ­stica general, Data Profiling**

```{r echo=F, warning=FALSE, error=FALSE, message=FALSE}

kable(df_numeric, format.args = list(big.mark=",", scientific=F))
```

Podemos decir del PM2.5 que es una variable numÃ©rica que va del 0 al 994, con una desviaciÃ³n estÃ¡ndar de 92. AdemÃ¡s, la media de esta variable es 98, lo que significa que los nÃºmeros mayores a 200 deberÃ­an ser alarmantes que estan contenidos en menos del 25% de los datos. 
La temperatura en Beijing varía mucho a lo largo del año y en las distintas regions, va de  -19°C a 42°C.
DEWP es el grado de humedad,  va de 10° a 26° normalmente y cualquier valor arriba o abajo puede causar un gran disomfort para el ser humano ya que menor a 10°C incluso menor a 0°C puede ser demasaido seco o mayor a 30°C puede ser asfixiante. En Beijing vemos que va de -40° a 28° lo cual está relacionado con las teperaturas extremas a la sque llega a alcanzar.


```{r echo=F, warning=FALSE, error=FALSE, message=FALSE}

kable(df_categoric, format.args = list(big.mark=",", scientific=F))
``` 

Tenemos 5 aÃ±os, con una moda del 2013, 12 meses con una moda en Julio y 4 valores para cbwd con una moda de SE (South East).

Preparamos los datos
```{r echo = FALSE, warning = FALSE, message = FALSE}
#data$cbwd <- as.factor(as.numeric(data$cbwd))
data <- data[,-c(1,2,8)] #Quitamos year, momnth, cbwd
data1 <- data
data1 %>%
  gather(-pm2.5, key = "some_var_name", value = "numeric_values") %>%
  ggplot(aes(x =  numeric_values, y =  pm2.5)) +
    geom_point() +
    facet_wrap(~ some_var_name, scales = "free")

data_scale <- scale(data)

data2 <- data_scale
data2 %>%
  gather(-pm2.5, key = "some_var_name", value = "numeric_values") %>%
  ggplot(aes(x =  numeric_values, y =  pm2.5)) +
    geom_point() +
    facet_wrap(~ some_var_name, scales = "free")
```
```{r echo = FALSE, warning = FALSE, message = FALSE}
summary(data_scale)
```

###K-means
También podemos observar que los datos no están en la misma escala por lo que tendr
```{r echo = TRUE, warning=FALSE, message=FALSE}

```


###Dendograma

Nota: "Ocupa average linkeage"
```{r echo = TRUE, warning=FALSE, message=FALSE}
distance_matrix <- dist(data)
#dendogram_complete <- hclust(distance_matrix,method="complete")
#ggdendrogram(dendogram_complete, rotate=F, size =2)

```

###Preguntas

1. k-means

    + CuÃ¡ntos grupos generaste, justificaciÃ³n 
    + CaracterÃ­sticas de cada grupo
    + Centroides obtenidos
    + Â¿CuÃ¡ntos elementos hay por grupo? 
    + Â¿Los grupos estÃ¡n balanceados? 
    
    
2. Dendogramas

    + Ocupa *average-linkage*
    + De acuerdo al $k$ obtenido en la pregunta anterior genera el corte al dendograma y genera los grupos
    + Â¿CuÃ¡ntos elementos hay por grupo? 
    + Â¿Los grupos estÃ¡n balanceados? 
    + CaracterÃ­sticas de cada grupo
    
    
3. Diferencias entre las caracterÃ­sticas de cada grupo


###Conclusiones

