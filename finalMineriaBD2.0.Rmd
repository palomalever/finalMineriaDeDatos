---
title: "Examen_Final_DIP"
author: '150074'
date: "6/12/2017"
output: html_document
---

#Examen Final Miner??a de Datos Agosto Diciembre 2017
###142213   David Alcalde
###150074 Iovannah Rudoy
###150553 Paloma Lever

 

## Agenda {.tabset .tabset-fade .tabset-pills}

+ Tema
+ Introducción
+ Datos
+ K-means
+ Dendograma
+ Preguntas
+ Conclusiones



###Tema

A nuestro equipo le fue asignado el siguiente tema (tema 2) en la clase del 4 de Diciembre del 2017:

*Agrupación*

Para este utilizamos una base de datos que contiene información relacionada con los niveles de contaminación de la ciudad de Beijing del 2010 al 2014. Con estos utilizamos k-means con todos los datos numéricos para agrupar en 7 clusters los datos, y después utilizamos los datos del 2014 para crear también 7 clusters. 


#### Agrupación

Cuentas con un set de datos que contiene información relacionada a la contaminación de Beijing -**PM2.5**- del 1 de enero de 2010 al 31 de diciembre del 2014. El set cuenta con las siguientes variables 

+ **No:** número de la observación (no consideramos que esto nos de información relevante)
+ **year:** año de la observación
+ **month:** mes de la observaciòn
+ **day:** día de la observación
+ **hour:** hora de la observación
+ **pm2.5:** PM2.5 concentration ($ug/m^3$) Este es el nivel de contaminación en la ciudad en ese momento.
+ **DEWP:** Dew Point, es una medida de la humedad en el ambiente
+ **TEMP:** Temperatura
+ **PRES:** Presión ambiental (hPa)
+ **cbwd:** Dirección del viento
+ **lws:** Velocidad del viento acumulada (m/s)
+ **ls:** Horas acumuladas de nieve
+ **lr:** Horas acumuladas de lluvia


###Introducción 

La contaminación es una de las consecuencias inmediatas de la industrialización y de la tecnificación de la vida y afecta principalmente al medio ambiente y a la salud de las personas. A lo largo de los años, ésta ha dejado una densa capa sobre las ciudades más pobladas convirtiéndola en una amenaza para la salud pública. En muchas ciudades como Beijing y la Ciudad de México se han buscado implementar grandes medidas para intentar mantenerla bajo control y combatir este fenómeno.

El Colegio de Medio Ambiente de la Unversidad de Nanjing relacionó la contaminación con casi un tercio de todas las muertes que se producen en China, poniendo a la polución en el mismo nivel que fumar tabaco. Diversas medidas se han hecho en China para bajar el nivel de polución como lo es establecer políticas de "No Circula"" para autos que no cumplen ciertos criterios, prohibir la producción a empresas que contaminan notablemente por unas horas al día e incluso invertir más en centros de investigación para encontrar una solucion más permamente y eficiente a este problema.

Contando con el set de datos que contiene información relevante respecto al nivel de contaminación de la ciudad de Bejing en 5 años, el objetivo es lograr la agrupación de los datos mediante el uso de dos métodos no supervisados: k-means clustering y dendogramas, para así poder centrar nuestro análisis en estos grupos que comparten diversas características entre sí y reconocer qué es lo que los hace únicos como grupos.


###Datos

```{r echo = FALSE, warning = FALSE, message=FALSE}
library(readr)
library(tidyverse)
library(ggplot2)
library(plotly)
library(stringr)
library(dplyr)
library(class) 
library(C50)
library(ROCR)
library(caret) 
library(knitr) 
library(tidyr)
library(rpart)
library(MLmetrics)
library(lubridate)
library(ggdendro)
library(stringr)
setwd(".")


data_prof <- function(d_set){
totals<-dim(d_set)[1]

#Obtención de las clases de cada columna
classes <- sapply(d_set, function(x) class(x))
categoricals <- d_set[,which(classes %in% c("character", "factor"))]
numerics <- d_set[,-which(classes %in% c("character", "factor"))]

#Número de valores únicos por campo
uniques_num <- sapply(numerics, function(x) unique(x) %>% length())
uniques_num <- as.data.frame(uniques_num)
uniques_cat <- sapply(categoricals, function(x) unique(x) %>% length())
uniques_cat <- as.data.frame(uniques_cat)

#Obtención de valores
uniques_num_values <- sapply(numerics, function(x) unique(x))
uniques__cat_values <- sapply(categoricals, function(x) unique(x))

#Proporción de valores únicos - totales
uniqueness_num <-  round(uniques_num/totals * 100, 2)
uniqueness_num <- as.data.frame(uniqueness_num)

uniqueness_cat <-  round(uniques_cat/totals * 100, 2)
uniqueness_cat <- as.data.frame(uniqueness_cat)

#Conteo de valores vac??os
nan_num <- sapply(numerics, function(x) sum(is.na(x)))
nan_num <- as.data.frame(nan_num)

#Se modifica para que lea valores vac??os y no precisamente Na
nan_cat <- sapply(categoricals, function(x) sum(is.na(x)))
nan_cat <- as.data.frame(nan_cat)

#Moda
modes_num <- sapply(numerics, function(x) Moda(x))
modes_num <- as.data.frame(modes_num)

modes_cat <- sapply(categoricals, function(x) Moda(x))
modes_cat <- as.data.frame(modes_cat)

#M??nimo
mins <- sapply(numerics, function(x) min(x))
mins <- as.data.frame(mins)

#Máximo
maxs <- sapply(numerics, function(x) max(x))
maxs <- as.data.frame(maxs)

#Promedio
means <- sapply(numerics, function(x) mean(x))
means <- as.data.frame(means)

#Mediana
medians <- sapply(numerics, function(x) median(x))
medians <- as.data.frame(medians)

#Primer quartil
first_qtls <- sapply(numerics, function(x) quantile(x, na.rm=T)[2])
first_qtls <- as.data.frame(first_qtls)

#Tercer quartil
third_qtls <- sapply(numerics, function(x) quantile(x, na.rm=T)[4])
third_qtls <- as.data.frame(third_qtls)

#Desviación estandar
sds <- sapply(numerics, function(x) sd(x))
sds <- as.data.frame(sds)


#Tabla de columnas categóricas
df_categoricals <- cbind(uniques_cat, uniqueness_cat, nan_cat, modes_cat)
names(df_categoricals) <- c("Unicos","Uniqueness (%)","Vac??os","Moda")


#Tabla de columnas numéricas
df_numericals <- cbind(uniques_num, uniqueness_num, nan_num, mins, maxs, means, medians, modes_num, first_qtls, third_qtls,sds) 
names(df_numericals) <- c("Unicos","Uniqueness (%)","Vac??os","M??nimo","Máximo","Promedio","Mediana","Moda","1er quartil","3er quartil","D. E.")
return(list(nums=df_numericals, cats=df_categoricals))
}


```





```{r warning=FALSE,message=FALSE}
#Iovannah
data <- read_csv('~/Desktop/Mineria_de_datos/pollution.csv')

#Paloma
#data <- read_csv("../data/pollution.csv")
summary(data)
rows <- nrow(data)
```
+ El set de datos cuenta con el siguiente numero de columnas: `r ncol(data)`
+ El set de datos cuenta con las siguientes variables: `r names(data)`
+ El set de datos cuenta con el siguiente numero de observaciones: `r dim(data)[1]`

Como podemos observar del primer resumen, pm2.5 es la variable con mas NA's. De un set que cuenta con `r rows` observaciones, 2,067 son NA's en pm2.5, ese es el `r (2067/rows * 100)`% de los datos, que es muy chico, por lo que para nuestro análisis futuro vamos a quitarlo utilizando el comando na.omit().

También podemos ver que la variable número y la variable día no dan realmente información por lo que igual los quitamos antes de hacer un análisis más detallado. Por requerimientos del trabajo, se nos pidió que quitáramos año, mes, día y No. pero para hacer el primer data profiling nos importa utilizar las variables año y mes.

```{r warning=FALSE}
set.seed(142213)

#Eliminamos los NAs para poder hacer el clustering.
data <- na.omit(data)

#Quitamos numero y dia
data<- data[,-c(1,4)]
data$year <- factor(data$year)
data$month <- factor(data$month)

```


```{r echo = FALSE, warning = FALSE, message=FALSE}

clases <- sapply(data, function(x) class(x))

#variables categoricas y numericas
categoricas <- data[,which(clases %in% c("character", "factor"))]
numericas <- data[,-which(clases %in% c("character", "factor"))]

#cardinalidad
uniques_num <- sapply(numericas, function(x) unique(x) %>% length())
uniques_num <- as.data.frame(uniques_num)

uniques_cat <- sapply(categoricas, function(x) unique(x) %>% length())
uniques_cat <- as.data.frame(uniques_cat)

#valores unicos

valores_unicos_num <- sapply(numericas, function(x) unique(x))
hvalores_unicos_cat <- sapply(categoricas, function(x) unique(x))

#uniqueness

porcentaje_unicos_num <-  round(uniques_num/(nrow(data)-1) * 100, 2)
porcentaje_unicos_num <- as.data.frame(porcentaje_unicos_num)

porcentaje_unicos_cat <- round(uniques_cat/(nrow(data)-1) * 100, 2)
porcentaje_unicos_cat$lk <- as.data.frame(porcentaje_unicos_cat)

#vac??os

nan_num <- sapply(numericas, function(x) sum(is.na(x)))
nan_num <- as.data.frame(nan_num)

nan_cat <- sapply(categoricas, function(x) sum(is.na(x)))
nan_cat <- as.data.frame(nan_cat)

#Función de Moda
Moda <- function(x){
  if (class(x) %in% c("character", "factor")) {
    table(x) %>%
      which.max() %>%
      names()
  }
  else {
    table(round(x, 2)) %>%
      which.max() %>%
      names()
  }
}

#moda
moda_num <- sapply(numericas, function(x) Moda(x))
moda_num <- as.data.frame(moda_num)

moda_cat <- sapply(categoricas, function(x) Moda(x))
moda_cat <- as.data.frame(moda_cat)

#M??nimo
minimo <- sapply(numericas, function(x) min(x))
minimo <- as.data.frame(minimo)

#Máximo
maximo <- sapply(numericas, function(x) max(x))
maximo <- as.data.frame(maximo)

#Promedio
promedio <- sapply(numericas, function(x) mean(x))
promedio <- as.data.frame(promedio)

#Mediana
mediana <- sapply(numericas, function(x) median(x))
mediana <- as.data.frame(mediana)

#Primer cuartil
primer_cuartil <- sapply(numericas, function(x) quantile(x)[2]) 
primer_cuartil <- as.data.frame(primer_cuartil)

#Tercer cuartil
tercer_cuartil <- sapply(numericas, function(x) quantile(x)[4]) 
tercer_cuartil <- as.data.frame(tercer_cuartil)

#Desviación estándar
desvest <- sapply(numericas, function(x) sd(x))
desvest <- as.data.frame(desvest)

#Tabla de data profiling
df_categoric <- cbind(uniques_cat, nan_cat, moda_cat)
names(df_categoric) <- str_replace_all(names(df_categoric), "_cat", "")

df_numeric <- cbind(uniques_num, nan_num, minimo, maximo, promedio, desvest,
                    mediana, moda_num, primer_cuartil, tercer_cuartil) 
names(df_numeric) <- str_replace_all(names(df_numeric), "_num", "")

kable(df_numeric, format.args = list(big.mark=",", scientific=F))
kable(df_categoric, format.args = list(big.mark=",", scientific = F))
names(df_categoric)[2]<-"uniqueness"

names(df_numeric)[2]<-"uniqueness"


```

**Estadística general, Data Profiling*
```{r echo=F, warning=FALSE, error=FALSE, message=FALSE}
kable(df_numeric, format.args = list(big.mark=",", scientific=F))
```

Podemos decir del PM2.5 que es una variable numérica que va del 0 al 994, con una desviacion estándar de 92. Esto nos indica uqe hay días muy peligrosos respecto a la contaminación en Beijing, debido a que según las escalas de peligro del pm2.5, a partir de 150 se considera peligroso. Afortunadamente, el 75% de los datos es menor a 137 (esto indica que es peligroso para grupos sensibles, como niños y adultos mayores) pero aún así es importante recalcar esto. 

La temperatura en Beijing varía mucho a lo largo del año y en las distintas regiones, va de -19C a 42C, con el 75% de los datos menores a 23C.

DEWP es el grado de humedad, normalmente va de 10 a 26 grados y cualquier valor arriba o abajo puede causar un gran disomfort para el ser humano ya que menor a 10?C incluso menor a 0?C puede ser demasaido seco o mayor a 30?C puede ser asfixiante. En Beijing vemos que va de -40 a 28 lo cual está relacionado con las teperaturas extremas a las que llega a alcanzar.

Además la velocidad del viento va de 0.45 a 565.4 m/s, lo que es muy alto. Es probable que cuando hay un mayor viento, el pm2.5 se reduzca. Finalmente, las horas de lluvia y de nieve son en su mayoría 0, pero llega a haber hasta 27 y 36 horas respectivamente.



```{r echo=F, warning=FALSE, error=FALSE, message=FALSE}

kable(df_categoric, format.args = list(big.mark=",", scientific=F))
``` 

Tenemos 5 años, con una moda del 2013, 12 meses con una moda en Julio y 4 valores para cbwd con una moda de SE (South East).

Ahora preparamos los datos para hacer clustering, quitamos las variables categoricas que no nos van a servir para hacer los clusters y luego las pondremos haciendo cbind con el dataset que tiene los clusters para  utilizarlas como análisis en el data profiling.

```{r echo = FALSE, warning = FALSE, message = FALSE}
#data$cbwd <- as.factor(as.numeric(data$cbwd))
data_previo <- data
data <- data[,-c(1,2,8)] #Quitamos year, month, cbwd
data1 <- data
data1 %>%
  gather(-pm2.5, key = "some_var_name", value = "numeric_values") %>%
  ggplot(aes(x =  numeric_values, y =  pm2.5)) +
    geom_point() +
    facet_wrap(~ some_var_name, scales = "free")
```

Al ver los datos podemos observar que la hora no es un dato constante.
```{r echo = FALSE, warning = FALSE, message = FALSE}
data_scale <- scale(data) %>% as.data.frame()
summary(data_scale)
```

###K-means
Las variables que más nos interesan para aplicar el algoritmo son las numéricas por lo que quitamos CBWD, año y mes.

+¿Cuántos grupos generaste? 

Para decidir el numero de grupos, hacemos el metodo del codo generando hasta 10 clusters. 
```{r echo = TRUE, warning=FALSE, message=FALSE}
retail_scaled <- data_scale

k_2  <- kmeans(retail_scaled, centers=2, iter.max=10)
k_3  <- kmeans(retail_scaled, centers=3, iter.max=10)
k_4  <- kmeans(retail_scaled, centers=4, iter.max=10)
k_5  <- kmeans(retail_scaled, centers=5, iter.max=10)
k_6  <- kmeans(retail_scaled, centers=6, iter.max=10)
k_7  <- kmeans(retail_scaled, centers=7, iter.max=10)
k_8  <- kmeans(retail_scaled, centers=8, iter.max=10)
k_9  <- kmeans(retail_scaled, centers=9, iter.max=10)
k_10 <- kmeans(retail_scaled, centers=10, iter.max=10)

tot_sumsquares <- k_2$totss

elbow_data <- data.frame(clusters = c(2,3,4,5,6,7,8,9,10),
                         sum_squares =c(k_2$tot.withinss/tot_sumsquares,
                                        k_3$tot.withinss/tot_sumsquares,
                                        k_4$tot.withinss/tot_sumsquares,
                                        k_5$tot.withinss/tot_sumsquares,
                                        k_6$tot.withinss/tot_sumsquares,
                                        k_7$tot.withinss/tot_sumsquares,
                                        k_8$tot.withinss/tot_sumsquares,
                                        k_9$tot.withinss/tot_sumsquares,
                                        k_10$tot.withinss/tot_sumsquares
                                        ))

ggplot(elbow_data, aes(x=clusters, y=sum_squares)) +
  geom_point() +
  geom_line() +
  theme_bw()
```

Con el metodo del codo vemos que el punto óptimo es tener 7 clusters ya que si eligieramos 6 veríamos que aún sigue bajando la suma de cuadrados y con 8 y 9 la diferencia que hay es menor a 0.1.

```{r}
table(k_7$cluster)
```

Podemos observar las coordenadas de cada centroide:

```{r}
k_7$centers
```

Para ver la distribución de los clusters de acuerdo a cada gráfica lo que hicimos, fue graficar cada punto con respecto a pm2.5 que es la variable que más nos interesa pra este set de datos. Los colores se van a juntar entre sí por que en realidad los clusters que se hicieron fue en 9 dimensiones por lo que al expresarlo en 2 no se va a ver con claridad cómo se eligió cada cluster pero si nos da una idea de cómo estan con respecto a cada variable.

```{r}
centroides <- as.data.frame(k_7$centers)
centroides$center <- "Y"
centroides$cluster <- "centroide"

data_clustered <- data_scale
data_clustered$cluster <- k_7$cluster
data_clustered$center <- "N"
data_clustered_centroides <- rbind(data_clustered,centroides)



ggplot(data_clustered_centroides, aes(x=data_clustered_centroides$DEWP, 
                                      y=data_clustered_centroides$pm2.5,
                                      color= as.factor(cluster), shape=center)) + geom_point() + scale_color_brewer(palette="Spectral",
                                                           name="Cluster") + theme_bw()

ggplot(data_clustered_centroides, aes(x=data_clustered_centroides$hour, 
                                      y=data_clustered_centroides$pm2.5,
                                      color= as.factor(cluster), shape=center)) + geom_point() + scale_color_brewer(palette="Spectral",
                                                           name="Cluster") + theme_bw()

ggplot(data_clustered_centroides, aes(x=data_clustered_centroides$TEMP, 
                                      y=data_clustered_centroides$pm2.5,
                                      color= as.factor(cluster), shape=center)) + geom_point() + scale_color_brewer(palette="Spectral",
                                                           name="Cluster") + theme_bw()

ggplot(data_clustered_centroides, aes(x=data_clustered_centroides$PRES, 
                                      y=data_clustered_centroides$pm2.5,
                                      color= as.factor(cluster), shape=center)) + geom_point() + scale_color_brewer(palette="Spectral",
                                                           name="Cluster") + theme_bw()

ggplot(data_clustered_centroides, aes(x=data_clustered_centroides$Iws, 
                                      y=data_clustered_centroides$pm2.5,
                                      color= as.factor(cluster), shape=center)) + geom_point() + scale_color_brewer(palette="Spectral",
                                                           name="Cluster") + theme_bw()

ggplot(data_clustered_centroides, aes(x=data_clustered_centroides$Is, 
                                      y=data_clustered_centroides$pm2.5,
                                      color= as.factor(cluster), shape=center)) + geom_point() + scale_color_brewer(palette="Spectral",
                                                           name="Cluster") + theme_bw()

ggplot(data_clustered_centroides, aes(x=data_clustered_centroides$Ir, 
                                      y=data_clustered_centroides$pm2.5,
                                      color= as.factor(cluster), shape=center)) + geom_point() + scale_color_brewer(palette="Spectral",
                                                           name="Cluster") + theme_bw()

```

####Data Profiling

```{r echo = TRUE, warning=FALSE, message=FALSE}

data <- cbind(data_previo,data_clustered$cluster)

```

```{r}
names(data) <- c("year", "month" ,"hour", "pm2.5", "DEWP", "TEMP", "PRES","cbwd" ,"Iws", "Is", "Ir", "cluster")
data$pm2.5 <- as.numeric(data$pm2.5)
cluster1 <- filter(data,data$cluster == 1)
cluster2 <- filter(data,data$cluster == 2)
cluster3 <- filter(data,data$cluster == 3)
cluster4 <- filter(data,data$cluster == 4)
cluster5 <- filter(data,data$cluster == 5)
cluster6 <- filter(data,data$cluster == 6)
cluster7 <- filter(data,data$cluster == 7)

```

Cluster 1

```{r echo = FALSE, warning = FALSE, message=FALSE}
cluster1$pm2.5 <- as.numeric(cluster1$pm2.5)

#variables categoricas y numericas
categoricas <- cluster1[,which(clases %in% c("character", "factor"))]
numericas <- cluster1[,-which(clases %in% c("character", "factor"))]

#cardinalidad
uniques_num <- sapply(numericas, function(x) unique(x) %>% length())
uniques_num <- as.data.frame(uniques_num)

uniques_cat <- sapply(categoricas, function(x) unique(x) %>% length())
uniques_cat <- as.data.frame(uniques_cat)

#valores unicos

valores_unicos_num <- sapply(numericas, function(x) unique(x))
hvalores_unicos_cat <- sapply(categoricas, function(x) unique(x))

#uniqueness

porcentaje_unicos_num <-  round(uniques_num/(nrow(cluster1)-1) * 100, 2)
porcentaje_unicos_num <- as.data.frame(porcentaje_unicos_num)

porcentaje_unicos_cat <- round(uniques_cat/(nrow(cluster1)-1) * 100, 2)
porcentaje_unicos_cat$lk <- as.data.frame(porcentaje_unicos_cat)

#vac??os

nan_num <- sapply(numericas, function(x) sum(is.na(x)))
nan_num <- as.data.frame(nan_num)

nan_cat <- sapply(categoricas, function(x) sum(is.na(x)))
nan_cat <- as.data.frame(nan_cat)

#moda
moda_num <- sapply(numericas, function(x) Moda(x))
moda_num <- as.data.frame(moda_num)

moda_cat <- sapply(categoricas, function(x) Moda(x))
moda_cat <- as.data.frame(moda_cat)

#M??nimo
minimo <- sapply(numericas, function(x) min(x))
minimo <- as.data.frame(minimo)

#Máximo
maximo <- sapply(numericas, function(x) max(x))
maximo <- as.data.frame(maximo)

#Promedio
promedio <- sapply(numericas, function(x) mean(x))
promedio <- as.data.frame(promedio)

#Mediana
mediana <- sapply(numericas, function(x) median(x))
mediana <- as.data.frame(mediana)

#Primer cuartil
primer_cuartil <- sapply(numericas, function(x) quantile(x)[2]) 
primer_cuartil <- as.data.frame(primer_cuartil)

#Tercer cuartil
tercer_cuartil <- sapply(numericas, function(x) quantile(x)[4]) 
tercer_cuartil <- as.data.frame(tercer_cuartil)

#Desviación estándar
desvest <- sapply(numericas, function(x) sd(x))
desvest <- as.data.frame(desvest)

#Tabla de data profiling
df_categoric <- cbind(uniques_cat, nan_cat, moda_cat)
names(df_categoric) <- str_replace_all(names(df_categoric), "_cat", "")

df_numeric <- cbind(uniques_num, nan_num, minimo, maximo, promedio, desvest,
                    mediana, moda_num, primer_cuartil, tercer_cuartil) 
names(df_numeric) <- str_replace_all(names(df_numeric), "_num", "")

kable(df_numeric, format.args = list(big.mark=",", scientific=F))
kable(df_categoric, format.args = list(big.mark=",", scientific = F))
```


Cluster 2

```{r echo = FALSE, warning = FALSE, message=FALSE}

#variables categoricas y numericas
categoricas <- cluster2[,which(clases %in% c("character", "factor"))]
numericas <- cluster2[,-which(clases %in% c("character", "factor"))]

#cardinalidad
uniques_num <- sapply(numericas, function(x) unique(x) %>% length())
uniques_num <- as.data.frame(uniques_num)

uniques_cat <- sapply(categoricas, function(x) unique(x) %>% length())
uniques_cat <- as.data.frame(uniques_cat)

#valores unicos

valores_unicos_num <- sapply(numericas, function(x) unique(x))
hvalores_unicos_cat <- sapply(categoricas, function(x) unique(x))

#uniqueness

porcentaje_unicos_num <-  round(uniques_num/(nrow(cluster2)-1) * 100, 2)
porcentaje_unicos_num <- as.data.frame(porcentaje_unicos_num)

porcentaje_unicos_cat <- round(uniques_cat/(nrow(cluster2)-1) * 100, 2)
porcentaje_unicos_cat$lk <- as.data.frame(porcentaje_unicos_cat)

#vac??os

nan_num <- sapply(numericas, function(x) sum(is.na(x)))
nan_num <- as.data.frame(nan_num)

nan_cat <- sapply(categoricas, function(x) sum(is.na(x)))
nan_cat <- as.data.frame(nan_cat)

#moda
moda_num <- sapply(numericas, function(x) Moda(x))
moda_num <- as.data.frame(moda_num)

moda_cat <- sapply(categoricas, function(x) Moda(x))
moda_cat <- as.data.frame(moda_cat)

#M??nimo
minimo <- sapply(numericas, function(x) min(x))
minimo <- as.data.frame(minimo)

#Máximo
maximo <- sapply(numericas, function(x) max(x))
maximo <- as.data.frame(maximo)

#Promedio
promedio <- sapply(numericas, function(x) mean(x))
promedio <- as.data.frame(promedio)

#Mediana
mediana <- sapply(numericas, function(x) median(x))
mediana <- as.data.frame(mediana)

#Primer cuartil
primer_cuartil <- sapply(numericas, function(x) quantile(x)[2]) 
primer_cuartil <- as.data.frame(primer_cuartil)

#Tercer cuartil
tercer_cuartil <- sapply(numericas, function(x) quantile(x)[4]) 
tercer_cuartil <- as.data.frame(tercer_cuartil)

#Desviación estándar
desvest <- sapply(numericas, function(x) sd(x))
desvest <- as.data.frame(desvest)

#Tabla de data profiling
df_categoric <- cbind(uniques_cat, nan_cat, moda_cat)
names(df_categoric) <- str_replace_all(names(df_categoric), "_cat", "")

df_numeric <- cbind(uniques_num, nan_num, minimo, maximo, promedio, desvest,
                    mediana, moda_num, primer_cuartil, tercer_cuartil) 
names(df_numeric) <- str_replace_all(names(df_numeric), "_num", "")

kable(df_numeric, format.args = list(big.mark=",", scientific=F))
kable(df_categoric, format.args = list(big.mark=",", scientific = F))
```


Cluster 3

```{r echo = FALSE, warning = FALSE, message=FALSE}

#variables categoricas y numericas
categoricas <- cluster3[,which(clases %in% c("character", "factor"))]
numericas <- cluster3[,-which(clases %in% c("character", "factor"))]

#cardinalidad
uniques_num <- sapply(numericas, function(x) unique(x) %>% length())
uniques_num <- as.data.frame(uniques_num)

uniques_cat <- sapply(categoricas, function(x) unique(x) %>% length())
uniques_cat <- as.data.frame(uniques_cat)

#valores unicos

valores_unicos_num <- sapply(numericas, function(x) unique(x))
hvalores_unicos_cat <- sapply(categoricas, function(x) unique(x))

#uniqueness

porcentaje_unicos_num <-  round(uniques_num/(nrow(cluster3)-1) * 100, 2)
porcentaje_unicos_num <- as.data.frame(porcentaje_unicos_num)

porcentaje_unicos_cat <- round(uniques_cat/(nrow(cluster3)-1) * 100, 2)
porcentaje_unicos_cat$lk <- as.data.frame(porcentaje_unicos_cat)

#vac??os

nan_num <- sapply(numericas, function(x) sum(is.na(x)))
nan_num <- as.data.frame(nan_num)

nan_cat <- sapply(categoricas, function(x) sum(is.na(x)))
nan_cat <- as.data.frame(nan_cat)

#moda
moda_num <- sapply(numericas, function(x) Moda(x))
moda_num <- as.data.frame(moda_num)

moda_cat <- sapply(categoricas, function(x) Moda(x))
moda_cat <- as.data.frame(moda_cat)

#M??nimo
minimo <- sapply(numericas, function(x) min(x))
minimo <- as.data.frame(minimo)

#Máximo
maximo <- sapply(numericas, function(x) max(x))
maximo <- as.data.frame(maximo)

#Promedio
promedio <- sapply(numericas, function(x) mean(x))
promedio <- as.data.frame(promedio)

#Mediana
mediana <- sapply(numericas, function(x) median(x))
mediana <- as.data.frame(mediana)

#Primer cuartil
primer_cuartil <- sapply(numericas, function(x) quantile(x)[2]) 
primer_cuartil <- as.data.frame(primer_cuartil)

#Tercer cuartil
tercer_cuartil <- sapply(numericas, function(x) quantile(x)[4]) 
tercer_cuartil <- as.data.frame(tercer_cuartil)

#Desviación estándar
desvest <- sapply(numericas, function(x) sd(x))
desvest <- as.data.frame(desvest)

#Tabla de data profiling
df_categoric <- cbind(uniques_cat, nan_cat, moda_cat)
names(df_categoric) <- str_replace_all(names(df_categoric), "_cat", "")

df_numeric <- cbind(uniques_num, nan_num, minimo, maximo, promedio, desvest,
                    mediana, moda_num, primer_cuartil, tercer_cuartil) 
names(df_numeric) <- str_replace_all(names(df_numeric), "_num", "")

kable(df_numeric, format.args = list(big.mark=",", scientific=F))
kable(df_categoric, format.args = list(big.mark=",", scientific = F))
```


Cluster 4

```{r echo = FALSE, warning = FALSE, message=FALSE}

#variables categoricas y numericas
categoricas <- cluster4[,which(clases %in% c("character", "factor"))]
numericas <- cluster4[,-which(clases %in% c("character", "factor"))]

#cardinalidad
uniques_num <- sapply(numericas, function(x) unique(x) %>% length())
uniques_num <- as.data.frame(uniques_num)

uniques_cat <- sapply(categoricas, function(x) unique(x) %>% length())
uniques_cat <- as.data.frame(uniques_cat)

#valores unicos

valores_unicos_num <- sapply(numericas, function(x) unique(x))
hvalores_unicos_cat <- sapply(categoricas, function(x) unique(x))

#uniqueness

porcentaje_unicos_num <-  round(uniques_num/(nrow(cluster4)-1) * 100, 2)
porcentaje_unicos_num <- as.data.frame(porcentaje_unicos_num)

porcentaje_unicos_cat <- round(uniques_cat/(nrow(cluster4)-1) * 100, 2)
porcentaje_unicos_cat$lk <- as.data.frame(porcentaje_unicos_cat)

#vac??os

nan_num <- sapply(numericas, function(x) sum(is.na(x)))
nan_num <- as.data.frame(nan_num)

nan_cat <- sapply(categoricas, function(x) sum(is.na(x)))
nan_cat <- as.data.frame(nan_cat)

#moda
moda_num <- sapply(numericas, function(x) Moda(x))
moda_num <- as.data.frame(moda_num)

moda_cat <- sapply(categoricas, function(x) Moda(x))
moda_cat <- as.data.frame(moda_cat)

#M??nimo
minimo <- sapply(numericas, function(x) min(x))
minimo <- as.data.frame(minimo)

#Máximo
maximo <- sapply(numericas, function(x) max(x))
maximo <- as.data.frame(maximo)

#Promedio
promedio <- sapply(numericas, function(x) mean(x))
promedio <- as.data.frame(promedio)

#Mediana
mediana <- sapply(numericas, function(x) median(x))
mediana <- as.data.frame(mediana)

#Primer cuartil
primer_cuartil <- sapply(numericas, function(x) quantile(x)[2]) 
primer_cuartil <- as.data.frame(primer_cuartil)

#Tercer cuartil
tercer_cuartil <- sapply(numericas, function(x) quantile(x)[4]) 
tercer_cuartil <- as.data.frame(tercer_cuartil)

#Desviación estándar
desvest <- sapply(numericas, function(x) sd(x))
desvest <- as.data.frame(desvest)

#Tabla de data profiling
df_categoric <- cbind(uniques_cat, nan_cat, moda_cat)
names(df_categoric) <- str_replace_all(names(df_categoric), "_cat", "")

df_numeric <- cbind(uniques_num, nan_num, minimo, maximo, promedio, desvest,
                    mediana, moda_num, primer_cuartil, tercer_cuartil) 
names(df_numeric) <- str_replace_all(names(df_numeric), "_num", "")

kable(df_numeric, format.args = list(big.mark=",", scientific=F))
kable(df_categoric, format.args = list(big.mark=",", scientific = F))
```

Cluster 5

```{r echo = FALSE, warning = FALSE, message=FALSE}

#variables categoricas y numericas
categoricas <- cluster5[,which(clases %in% c("character", "factor"))]
numericas <- cluster5[,-which(clases %in% c("character", "factor"))]

#cardinalidad
uniques_num <- sapply(numericas, function(x) unique(x) %>% length())
uniques_num <- as.data.frame(uniques_num)

uniques_cat <- sapply(categoricas, function(x) unique(x) %>% length())
uniques_cat <- as.data.frame(uniques_cat)

#valores unicos

valores_unicos_num <- sapply(numericas, function(x) unique(x))
hvalores_unicos_cat <- sapply(categoricas, function(x) unique(x))

#uniqueness

porcentaje_unicos_num <-  round(uniques_num/(nrow(cluster5)-1) * 100, 2)
porcentaje_unicos_num <- as.data.frame(porcentaje_unicos_num)

porcentaje_unicos_cat <- round(uniques_cat/(nrow(cluster5)-1) * 100, 2)
porcentaje_unicos_cat$lk <- as.data.frame(porcentaje_unicos_cat)

#vac??os

nan_num <- sapply(numericas, function(x) sum(is.na(x)))
nan_num <- as.data.frame(nan_num)

nan_cat <- sapply(categoricas, function(x) sum(is.na(x)))
nan_cat <- as.data.frame(nan_cat)

#moda
moda_num <- sapply(numericas, function(x) Moda(x))
moda_num <- as.data.frame(moda_num)

moda_cat <- sapply(categoricas, function(x) Moda(x))
moda_cat <- as.data.frame(moda_cat)

#M??nimo
minimo <- sapply(numericas, function(x) min(x))
minimo <- as.data.frame(minimo)

#Máximo
maximo <- sapply(numericas, function(x) max(x))
maximo <- as.data.frame(maximo)

#Promedio
promedio <- sapply(numericas, function(x) mean(x))
promedio <- as.data.frame(promedio)

#Mediana
mediana <- sapply(numericas, function(x) median(x))
mediana <- as.data.frame(mediana)

#Primer cuartil
primer_cuartil <- sapply(numericas, function(x) quantile(x)[2]) 
primer_cuartil <- as.data.frame(primer_cuartil)

#Tercer cuartil
tercer_cuartil <- sapply(numericas, function(x) quantile(x)[4]) 
tercer_cuartil <- as.data.frame(tercer_cuartil)

#Desviación estándar
desvest <- sapply(numericas, function(x) sd(x))
desvest <- as.data.frame(desvest)

#Tabla de data profiling
df_categoric <- cbind(uniques_cat, nan_cat, moda_cat)
names(df_categoric) <- str_replace_all(names(df_categoric), "_cat", "")

df_numeric <- cbind(uniques_num, nan_num, minimo, maximo, promedio, desvest,
                    mediana, moda_num, primer_cuartil, tercer_cuartil) 
names(df_numeric) <- str_replace_all(names(df_numeric), "_num", "")

kable(df_numeric, format.args = list(big.mark=",", scientific=F))
kable(df_categoric, format.args = list(big.mark=",", scientific = F))
```

Cluster 6

```{r echo = FALSE, warning = FALSE, message=FALSE}

#variables categoricas y numericas
categoricas <- cluster6[,which(clases %in% c("character", "factor"))]
numericas <- cluster6[,-which(clases %in% c("character", "factor"))]

#cardinalidad
uniques_num <- sapply(numericas, function(x) unique(x) %>% length())
uniques_num <- as.data.frame(uniques_num)

uniques_cat <- sapply(categoricas, function(x) unique(x) %>% length())
uniques_cat <- as.data.frame(uniques_cat)

#valores unicos

valores_unicos_num <- sapply(numericas, function(x) unique(x))
hvalores_unicos_cat <- sapply(categoricas, function(x) unique(x))

#uniqueness

porcentaje_unicos_num <-  round(uniques_num/(nrow(cluster6)-1) * 100, 2)
porcentaje_unicos_num <- as.data.frame(porcentaje_unicos_num)

porcentaje_unicos_cat <- round(uniques_cat/(nrow(cluster6)-1) * 100, 2)
porcentaje_unicos_cat$lk <- as.data.frame(porcentaje_unicos_cat)

#vac??os

nan_num <- sapply(numericas, function(x) sum(is.na(x)))
nan_num <- as.data.frame(nan_num)

nan_cat <- sapply(categoricas, function(x) sum(is.na(x)))
nan_cat <- as.data.frame(nan_cat)

#moda
moda_num <- sapply(numericas, function(x) Moda(x))
moda_num <- as.data.frame(moda_num)

moda_cat <- sapply(categoricas, function(x) Moda(x))
moda_cat <- as.data.frame(moda_cat)

#M??nimo
minimo <- sapply(numericas, function(x) min(x))
minimo <- as.data.frame(minimo)

#Máximo
maximo <- sapply(numericas, function(x) max(x))
maximo <- as.data.frame(maximo)

#Promedio
promedio <- sapply(numericas, function(x) mean(x))
promedio <- as.data.frame(promedio)

#Mediana
mediana <- sapply(numericas, function(x) median(x))
mediana <- as.data.frame(mediana)

#Primer cuartil
primer_cuartil <- sapply(numericas, function(x) quantile(x)[2]) 
primer_cuartil <- as.data.frame(primer_cuartil)

#Tercer cuartil
tercer_cuartil <- sapply(numericas, function(x) quantile(x)[4]) 
tercer_cuartil <- as.data.frame(tercer_cuartil)

#Desviación estándar
desvest <- sapply(numericas, function(x) sd(x))
desvest <- as.data.frame(desvest)

#Tabla de data profiling
df_categoric <- cbind(uniques_cat, nan_cat, moda_cat)
names(df_categoric) <- str_replace_all(names(df_categoric), "_cat", "")

df_numeric <- cbind(uniques_num, nan_num, minimo, maximo, promedio, desvest,
                    mediana, moda_num, primer_cuartil, tercer_cuartil) 
names(df_numeric) <- str_replace_all(names(df_numeric), "_num", "")

kable(df_numeric, format.args = list(big.mark=",", scientific=F))
kable(df_categoric, format.args = list(big.mark=",", scientific = F))
```


Cluster 7

```{r echo = FALSE, warning = FALSE, message=FALSE}

#variables categoricas y numericas
categoricas <- cluster7[,which(clases %in% c("character", "factor"))]
numericas <- cluster7[,-which(clases %in% c("character", "factor"))]

#cardinalidad
uniques_num <- sapply(numericas, function(x) unique(x) %>% length())
uniques_num <- as.data.frame(uniques_num)

uniques_cat <- sapply(categoricas, function(x) unique(x) %>% length())
uniques_cat <- as.data.frame(uniques_cat)

#valores unicos

valores_unicos_num <- sapply(numericas, function(x) unique(x))
hvalores_unicos_cat <- sapply(categoricas, function(x) unique(x))

#uniqueness

porcentaje_unicos_num <-  round(uniques_num/(nrow(cluster7)-1) * 100, 2)
porcentaje_unicos_num <- as.data.frame(porcentaje_unicos_num)

porcentaje_unicos_cat <- round(uniques_cat/(nrow(cluster7)-1) * 100, 2)
porcentaje_unicos_cat$lk <- as.data.frame(porcentaje_unicos_cat)

#vac??os

nan_num <- sapply(numericas, function(x) sum(is.na(x)))
nan_num <- as.data.frame(nan_num)

nan_cat <- sapply(categoricas, function(x) sum(is.na(x)))
nan_cat <- as.data.frame(nan_cat)

#moda
moda_num <- sapply(numericas, function(x) Moda(x))
moda_num <- as.data.frame(moda_num)

moda_cat <- sapply(categoricas, function(x) Moda(x))
moda_cat <- as.data.frame(moda_cat)

#M??nimo
minimo <- sapply(numericas, function(x) min(x))
minimo <- as.data.frame(minimo)

#Máximo
maximo <- sapply(numericas, function(x) max(x))
maximo <- as.data.frame(maximo)

#Promedio
promedio <- sapply(numericas, function(x) mean(x))
promedio <- as.data.frame(promedio)

#Mediana
mediana <- sapply(numericas, function(x) median(x))
mediana <- as.data.frame(mediana)

#Primer cuartil
primer_cuartil <- sapply(numericas, function(x) quantile(x)[2]) 
primer_cuartil <- as.data.frame(primer_cuartil)

#Tercer cuartil
tercer_cuartil <- sapply(numericas, function(x) quantile(x)[4]) 
tercer_cuartil <- as.data.frame(tercer_cuartil)

#Desviación estándar
desvest <- sapply(numericas, function(x) sd(x))
desvest <- as.data.frame(desvest)

#Tabla de data profiling
df_categoric <- cbind(uniques_cat, nan_cat, moda_cat)
names(df_categoric) <- str_replace_all(names(df_categoric), "_cat", "")

df_numeric <- cbind(uniques_num, nan_num, minimo, maximo, promedio, desvest,
                    mediana, moda_num, primer_cuartil, tercer_cuartil) 
names(df_numeric) <- str_replace_all(names(df_numeric), "_num", "")

kable(df_numeric, format.args = list(big.mark=",", scientific=F))
kable(df_categoric, format.args = list(big.mark=",", scientific = F))
```


#####Características de cada cluster

Cluster 1: "Final del 2013 con contaminación *mala-muy mala-peligrosa*"
Año: la mayor??a de los datos son del 2013
Mes: la mayor??a son de Octubre (mes 10)
cbwd: la mayor??a son datos que van a cv

hora: la más común es a las 11 pm, 
pm2.5: va de 140 a 994, con una moda de 227 y el 75% de los datos son menores a 343. (Son datos promedio)
DEWP: va de -25 a 27, con una moda de 5 y el 75% de los datos es menor a 4. Esto significa que la humedad va a los dos extremos. Pero en general es seco.
TEMP: va de -16 a 30, con una moda de -3 y el 75% son menores a 11. (Temperaturas bajas, pero no afectan la humedad)
PRES: va de 997 a 1037, con una moda de 1021 y poca desviación. 
Iws: va de 0.45 a 111.78, con una moda de 0.89 y el 75% es menor a 5. Por lo que hay poco viento (velocidad del viento).
Is: va de 0 a 5, con una moda de 0. Por lo que normalmente no hay nieve.
Ir: va de 0 a 6, con una moda de 0. Esto significa que casi no hay lluvia y como la lluvia disminuye la contaminación, se entiende que más del 75% de los datos tienen un pm2.5 mayor a 230.


Cluster 2: "Invierno con contaminación *moderada-mala*"
Año: la mayor??a son datos del 2012
Mes: la mayor??a son datos de Febrero (mes 2), nota: unicamente hay 4 meses en este cluster
cbwd: moda SE.

hora: la moda es de 11 am, el 75% son datos antes de las 15:00.
pm2.5: va de 21 a 453, con una moda de 68 y el 75% de los datos son menores a 133. Esto implica relativamente poca contaminación.
DEWP: va de -11 a 1, con una moda de -6 y el 75% de los datos son menores a -3. Esto significa que es un clima seco, pero no es extremo.
TEMP: va de -10 a 1, con una moda de -2 y el 75% de los datos son menores a -2. Esto es entendible por el mes (Febrero en general), además es entendible que la contaminación no sea muy alta, pues en general temperturas bajas implican menos contaminación.
PRES: va de 1017 a 1041, con una moda de 1020 y continúa habiendo poca varianza.
Iws: va de 0.45 a 127.84, con una moda de 0.89 y el 75% de los datos tiene valores menores a 66.63. Esto significa que la velocidad del aire es "media", puede contribuir a que la contaminación no sea tan elevada. Ya que en este cluster tiende a no ser mayor al nivel peligroso (pm2.5 = 220).
Is: va de 6 a 27 horas acumuladas de nieve, (se entiende por ser febrero).
Ir: no hay horas de lluvia (esto se entiende porque hay nieve, lo que sustituye a la lluvia)


Cluster 3: "Madrugada y calor, contaminación *moderada-mala para grupos sensibles*"
Año: la moda es del 2014
Mes: 7 (verano), 10 meses
cbwd: moda SE

hora: la moda es 00:00, y el 75% están antes de las 08:00 am.
pm2.5: va de 1 a 361, con una moda de 77 y el 75% son menores a 132 (relativamente poca contaminación, pocos elementos arriba del pm 2.5 considerado peligroso)
DEWP: va de -14 a 28, con una moda de 18 y el 75% se encuentran antes del 20. Relativamente humedo.
TEMP: va de 1 a 32, con moda 23 y el 75% antes de 23. El 50% entre 16 y 23. Esto es entendible por la época del año, calor medio.
PRES: va de 994 a 1029, es un poco menor a los otros clusters. Sigue habiendo poca varianza.
Iws: va de 0.45 a 208.79, con moda de 0.89 y el 75% menores a 9.84. Esto implica que hubo viento, pero no de muy altas velocidades.
Is: No hubo nieve.
Ir: el 75% de los datos no tuvieron horas de lluvia, pero se registraron hasta 36 horas seguidas de lluvia en algunas observaciones. 

Cluster 4: "Mucho calor, mucho viento y  contaminación *moderada* en la tarde"
Año: moda 2014
Mes: moda 7 (verano), con 9 meses 
cbwd: SE

hora: va de 14:00 a 20:00, con una moda de 17:00. Por lo que son datos en la tarde.
pm2.5: va de 1 a 399, el 75% son menores a 121, moda de 16. Por lo que la contaminación es moderada.
DEWP: va de -18 a 28, alto grado de humedad con moda 17. Humedo.
TEMP: va de 4 a 42, con una moda de 27. Por lo que son meses de mucho calor, cluster de más calor.1 
PRES: va de 991 a 1024, moda de 1006, por lo que continúa habiendo poca varianza. 
Iws: va de 0.45 a 171, con el 75% de los datos menores a 22.8. S?? hubo viento, incluso a veces a velocidades muy altas. Esto podr??a reducir la contaminación.
Is: no hubo horas de nieve (se entiende por la temperatura)
Ir: el 75% de los datos no tuvieron lluvia, pero va de 0 a 8horas de lluvia.


Cluster 5: "Principio de año, mucho viento, muy seco, en la tarde. Contaminación *moderada*"
Año: 2013
Mes: 3 (9 meses registrados)
cbwd: NW

hora: 50% de los datos están entre 14:00 y 20:00hrs, por lo que son en la tarde-noche a inicios de año
pm2.5: va de 2 a 238, el 75% son menores a 90. Esto implica que hubo poca contaminación.
DEWP: va de -40 a 13. Esto implica un clima *muy* seco. El 75% de los datos es menor a -5.
TEMP: va de - 18 a 26, con el 75% menor a 11, y una moda de 2. Por lo que hay una gran varianza de temperatura, pero son temperaturas fr??as en general. Esto podr??a tener una relación con la baja contaminación.
PRES: va de 1005 a 1042, con una moda de 1025. Poca varianza. 
Iws: va de 0.45 a 132.76, con el 75% menor a 30.85. Esto implica que hubo bastante viento.
Is: en el 75% de los datos no hubo horas de nieve, pero se registraron hasta 5 horas de nieve. Puede relacionarse con la época del año (fin invierno-inicio primavera).
Ir: en el 75% de los datos no hubo horas de lluvia, pero se registraron hasta 10 horas de lluvia.


Cluster 6: "Inicio de año en la madrugada, muy frío y muy seco contaminación *moderada*"
Año: 2010
Mes: 1 (inicios de año)
cbwd: NW

hora: 50% de los datos están entre 3:00 y 8:00hrs. (madrugada)
pm2.5: va de 2 a 275, el 75% son menores a 106. Poca contaminación, pero más alta que algunos otros.
DEWP: va de -35 a 9. Moda de -10 y el 75% de los datos es menor a -5. (muy seco)
TEMP: va de - 18 a 18, con el 75% menor a 3, y una moda de -3. (*Muy* frío, se entiende por la época del año).
PRES: va de 1007 a 1046, con una moda de 1027. Poca varianza. 
Iws: va de 0.45 a 127.83, con el 75% menor a 18.77.  (Poco viento)
Is: en el 75% de los datos no hubo horas de nieve, pero se registraron hasta 5 horas de nieve. 
Ir: en el 75% de los datos no hubo horas de lluvia, pero se registraron hasta 6 horas de lluvia.

Cluster 7: "MUCHISIMO VIENTO, contaminación *buena-moderada*"
Este es el cluster con los menores niveles de contaminación
Año: moda 2010
Mes: diciembre, datos de los 11 meses
cbwd: NW

hora: 50% de los datos están entre 06:00 y 18:00hrs. (horas laborales)
pm2.5: va de 0 a 276, el 75% son menores a 21. Moda 11. (Poca contaminación)
DEWP: va de -38 a 13. Moda de -20. El 75% de los datos es menor a -11.  Esto implica un clima *muy* seco
TEMP: va de - 19 a 29, con el 75% menor a 8, y una moda de -1. Clima fr??o en general.
PRES: va de 1001 a 1046, con una moda de 1027. Poca varianza. 
Iws: va de 109 a 565.49, con el 75% mayor a 150. Esto implica que hay *mucho* viento, es el cluster con el más viento. 
Is: no hubo nieve (0)
Ir: en el 75% de los datos no hubo horas de lluvia, pero se registraron hasta 1 hora de lluvia.


###Dendograma
Nota: "Ocupa average linkeage"
```{r echo = TRUE, warning=FALSE, message=FALSE}
data_2014 <- filter(data_previo,year==2014)

```


*Data profiling data_2014

```{r echo = FALSE, warning = FALSE, message=FALSE}
#variables categoricas y numericas
categoricas <- data_2014[,which(clases %in% c("character", "factor"))]
numericas <- data_2014[,-which(clases %in% c("character", "factor"))]

#cardinalidad
uniques_num <- sapply(numericas, function(x) unique(x) %>% length())
uniques_num <- as.data.frame(uniques_num)

uniques_cat <- sapply(categoricas, function(x) unique(x) %>% length())
uniques_cat <- as.data.frame(uniques_cat)

#valores unicos

valores_unicos_num <- sapply(numericas, function(x) unique(x))
hvalores_unicos_cat <- sapply(categoricas, function(x) unique(x))

#uniqueness

porcentaje_unicos_num <-  round(uniques_num/(nrow(data_2014)-1) * 100, 2)
porcentaje_unicos_num <- as.data.frame(porcentaje_unicos_num)

porcentaje_unicos_cat <- round(uniques_cat/(nrow(data_2014)-1) * 100, 2)
porcentaje_unicos_cat$lk <- as.data.frame(porcentaje_unicos_cat)

#vac??os

nan_num <- sapply(numericas, function(x) sum(is.na(x)))
nan_num <- as.data.frame(nan_num)

nan_cat <- sapply(categoricas, function(x) sum(is.na(x)))
nan_cat <- as.data.frame(nan_cat)

#Función de Moda
Moda <- function(x){
  if (class(x) %in% c("character", "factor")) {
    table(x) %>%
      which.max() %>%
      names()
  }
  else {
    table(round(x, 2)) %>%
      which.max() %>%
      names()
  }
}

#moda
moda_num <- sapply(numericas, function(x) Moda(x))
moda_num <- as.data.frame(moda_num)

moda_cat <- sapply(categoricas, function(x) Moda(x))
moda_cat <- as.data.frame(moda_cat)

#M??nimo
minimo <- sapply(numericas, function(x) min(x))
minimo <- as.data.frame(minimo)

#Máximo
maximo <- sapply(numericas, function(x) max(x))
maximo <- as.data.frame(maximo)

#Promedio
promedio <- sapply(numericas, function(x) mean(x))
promedio <- as.data.frame(promedio)

#Mediana
mediana <- sapply(numericas, function(x) median(x))
mediana <- as.data.frame(mediana)

#Primer cuartil
primer_cuartil <- sapply(numericas, function(x) quantile(x)[2]) 
primer_cuartil <- as.data.frame(primer_cuartil)

#Tercer cuartil
tercer_cuartil <- sapply(numericas, function(x) quantile(x)[4]) 
tercer_cuartil <- as.data.frame(tercer_cuartil)

#Desviación estándar
desvest <- sapply(numericas, function(x) sd(x))
desvest <- as.data.frame(desvest)

#Tabla de data profiling
df_categoric <- cbind(uniques_cat, nan_cat, moda_cat)
names(df_categoric) <- str_replace_all(names(df_categoric), "_cat", "")

df_numeric <- cbind(uniques_num, nan_num, minimo, maximo, promedio, desvest,
                    mediana, moda_num, primer_cuartil, tercer_cuartil) 
names(df_numeric) <- str_replace_all(names(df_numeric), "_num", "")

```

```{r echo = FALSE}
kable(df_categoric)
kable(df_numeric)
```

```{r echo = TRUE, warning=FALSE, message=FALSE}
##Usamos solo los datos del 2014 porque no funcionaba con todos los datos
data_2014_completo<-data_2014
data_2014 <- data_2014[,-c(1,2,8)]
data_2014_scaled <- scale(data_2014) %>% as.data.frame()

distance_matrix <- dist(data_2014_scaled)


dendogram_average <- hclust(distance_matrix,method="average")

ggdendrogram(dendogram_average, rotate=F, size =2)

```

Por nuestro gráfico de dendogramas, para tener menos de 10 grupos, utilizaremos un punto de corte de 7, debido a que vimos que esto es lo más eficiente para estos datos.

```{r echo = FALSE, warning=FALSE, message=FALSE}
library(ggplot2)

cut_average <- cutree(dendogram_average, k=10)

data_clusters <- data_2014_completo
data_clusters$grupo <- cut_average

table(data_clusters$grupo)

data_clusters$grupo<-as.factor(data_clusters$grupo)

#table(cut_average,data_2014$TEMP)

cut_average <- cutree(dendogram_average, k=7)
data_clusters$grupo <- cut_average
table(data_clusters$grupo)
data_clusters$grupo<-as.factor(data_clusters$grupo)
```

Realizamos 10 y 7 grupos para buscar continuar con la lógica de k-means, pero como vimos anteriormente es suficiente con 7 grupos para poder dividir los datos.


####**Grupo 1**

```{r echo=T, warning=F, error=F, message=F}
dp <- data_prof(filter(data_clusters,grupo == 1))
n1 <- nrow(filter(data_clusters,grupo == 1))
kable(dp$nums, format.args = list(big.mark=",", scientific=F), align = c(rep('c', 10))) 
kable(dp$cats, format.args = list(big.mark=",", scientific=F), align = c(rep('c', 4)))
```


####**Grupo 2**

```{r echo=T, warning=F, error=F, message=F}
dp <- data_prof(filter(data_clusters,grupo == 2))
n2 <- nrow(filter(data_clusters,grupo == 2))
kable(dp$nums, format.args = list(big.mark=",", scientific=F), align = c(rep('c', 10))) 
kable(dp$cats, format.args = list(big.mark=",", scientific=F), align = c(rep('c', 4)))
```

####**Grupo 3**

```{r echo=T, warning=F, error=F, message=F}
dp <- data_prof(filter(data_clusters,grupo == 3))
n3 <- nrow(filter(data_clusters,grupo == 3))
kable(dp$nums, format.args = list(big.mark=",", scientific=F), align = c(rep('c', 10))) 
kable(dp$cats, format.args = list(big.mark=",", scientific=F), align = c(rep('c', 4)))
```

####**Grupo 4**

```{r echo=T, warning=F, error=F, message=F}
dp <- data_prof(filter(data_clusters,grupo == 4))
n4 <- nrow(filter(data_clusters,grupo == 4))
kable(dp$nums, format.args = list(big.mark=",", scientific=F), align = c(rep('c', 10))) 
kable(dp$cats, format.args = list(big.mark=",", scientific=F), align = c(rep('c', 4)))
```

####**Grupo 5**

```{r echo=T, warning=F, error=F, message=F}
dp <- data_prof(filter(data_clusters,grupo == 5))
n5 <- nrow(filter(data_clusters,grupo == 5))
kable(dp$nums, format.args = list(big.mark=",", scientific=F), align = c(rep('c', 10))) 
kable(dp$cats, format.args = list(big.mark=",", scientific=F), align = c(rep('c', 4)))
```

####**Grupo 6**

```{r echo=T, warning=F, error=F, message=F}
dp <- data_prof(filter(data_clusters,grupo == 6))
n6 <- nrow(filter(data_clusters,grupo == 6))
kable(dp$nums, format.args = list(big.mark=",", scientific=F), align = c(rep('c', 10))) 
kable(dp$cats, format.args = list(big.mark=",", scientific=F), align = c(rep('c', 4)))
```

####**Grupo 7**

```{r echo=T, warning=F, error=F, message=F}
dp <- data_prof(filter(data_clusters,grupo == 7))
n7 <- nrow(filter(data_clusters,grupo == 7))
kable(dp$nums, format.args = list(big.mark=",", scientific=F), align = c(rep('c', 10))) 
kable(dp$cats, format.args = list(big.mark=",", scientific=F), align = c(rep('c', 4)))
```

####Características de cada grupo

Cluster 1: "Mayor cluster con más variedad de contaminación (*Buena-mala*), temperatura y horario"
Año : 2014
Mes : 3
CBWD: SE

Hora:  MODA: 2, el 50% de los datos estan entre las 5:00am y las 18pm 
pm2.5: Los datos van de 2 a 671 con moda= 11 y el 75% de los datos son menores a 135
DEWP:  El grado de humedad va de -40 a 25 grados con una moda de 18. Lo cual es medianamente h?medo y el 75% de los datos son menores a 15.
TEMP:  La temperatura va de -13 a 42 grados con una moda de 20, lo cual indica clima c?lido con el 75% de los datos menores a 23? 
PRES:  La presi?n va de 993 a 1039 con una moda de 1006.
Iws:   La velocidad del viento va de 0.45 a 230.23 con una moda de 0.89 con el 75% de los datos menores a 16.9 lo cual indica que hay entre medio y bajo viento. 
Is:    El 75% de los datos no registraron nieve y la m?xima cantidad de horas seguidas de nieve registradas son 3. 
Ir:    El 75% de los datos no registraron lluvia y la m?xima cantidad de horas seguidas de lluvia registradas son 7.

Cluster 2: "Vientos más fuertes, moderado a frío, cluster con menor contaminación (*BUENA*), menor humedad sin lluvias ni nevadas."
Es el primer grupo que contiene observaciones que siempre tienen niveles de pm2.5 considerados como bueno.
Año : 2014
Mes : 12
CBWD: NW

Hora:  MODA: 13, el 50% de los datos estan entre las 0:00am y las 15:00pm 
pm2.5: Los datos van de 3 a 60 con moda= 9 y el 75% de los datos son menores a 16. Esto indica que en este grupo hay muy poca contaminaci?n
DEWP:  El grado de humedad va de -27 a 2 grados con una moda de -20. Lo cual es muy seco, y el 75% de los datos son menores a -12.
TEMP:  La temperatura va de -9 a 24 grados con una moda de -3, lo cual indica clima bastante fr?o con el 75% de los datos menores a 13? 
PRES:  La presi?n va de 1005 a 1035 con una moda de 1032.
Iws:   La velocidad del viento va de 156.45 a 441.18 con una moda de 207.41 con el 75% de los datos menores a 318.26 lo cual indica que hay vientos muy fuertes.
Is:    No hay nieve. 
Ir:    No hay lluvia.

Cluster 3: "Inicio de año, mucho frío, nieve, viento y media contaminación (*Moderada-mala para grupos sensibles*) en la mañana"
Año :2014
Mes :2
CBWD:SE

Hora:  MODA: 9:00, el 50% de los datos estan entre las 9:00am y las 12:0 (son datos de la ma?ana) 
pm2.5: Los datos van de 84 a 112 con moda= 84 y el 75% de los datos son menores a 106. Indica contaminaci?n moderada.
DEWP:  El grado de humedad va de -7 a -6 grados con una moda de -7. Moderadamente seco con muy poca varianza.
TEMP:  La temperatura va de -5 a -3 grados con una moda de -4, lo cual indica clima bastante fr?o con el 75% de los datos menores a -3.5? 
PRES:  La presi?n va de 1025 a 1029 con una moda de 1029.
Iws:   La velocidad del viento va de 33.98 a 46-06 con una moda de 33.98 con el 75% de los datos menores a 42.70 lo cual indica que hay alto viento. 
Is:    Va de 4 a 10, con moda de 4 y el 75% menores a 8.5. Tiene sentido por las temperaturas fr?as y el viento. 
Ir:    No hubo lluvia.

Cluster 4: "Invierno, frío y nieve con viento moderado en la noche. Contaminación (*moderada-mala para grupos sensibles*)"
Año :2014
Mes :2
CBWD:SE


Hora:  MODA: 16:00, el 50% de los datos estan entre las 16:00am y las 19:30pm 
pm2.5: Los datos van de 98 a 109 con moda= 107 y el 75% de los datos son menores a 108.25. Contaminaci?n moderada.
DEWP:  El grado de humedad va de -7 a -6. Clima seco con muy poca varianza.
TEMP:  La temperatura va de -4 a -3. Temperaturas muy bajas con muy poca varianza.
PRES:  La presi?n va de 1024 a 1025.
Iws:   La velocidad del viento va de 47.85 a 63.06 con una moda de 47.85 con el 75% de los datos menores a 59.92 lo cual indica que hay alto viento, pero no es el m?s alto. 
Is:    Va de 11 a 18, con moda 11 y 75% de los datos menoresa 16.25
Ir:    No hay lluvia.

Cluster 5: "Invierno en la madrugada, cluster con más nieve, menor viento, más frío y contaminación *moderada-mala para grupos sensibles*"
Año :2014
Mes :2
CBWD:SE

Hora:  MODA: 00:00, el 50% de los datos estan entre las 1:00am y las 3am 
pm2.5: Los datos van de 88 a 115 con moda= 88 y el 75% de los datos son menores a 106. Contaminaci?n moderada.
DEWP:  El grado de humedad va de -7 a -6. Seco con muy poca varianza.
TEMP:  La temperatura es de -4.
PRES:  La presi?n va de 1024-1025.
Iws:   La velocidad del viento con una moda de 0.89, indica muy poco viento.
Is:    Moda de 19 horas, con maximo 23 horas. 
Ir:    No hay lluvia.

Cluster 6: "Otoño, lluvioso con moderado viento, cluster con mayor temperatura (templada) y contaminación *buena-moderada*."
Año :2014
Mes :9
CBWD:NW


Hora:  MODA: 4:00, el 50% de los datos estan entre las 4:00am y las 10:00am (ma?ana)
pm2.5: Los datos van de 17 a 116 con moda= 21 y el 75% de los datos son menores a 81. Contaminaci?n media baja.
DEWP:  El grado de humedad va de 7 a 23 grados con una moda de 18. Lo cual es medianamente h?medo y el 75% de los datos son menores a 18. Humedad moderada.
TEMP:  La temperatura va de 10 a 24 grados con una moda de 11, lo cual indica clima cálido con el 75% de los datos menores a 20. Temperatura moderada. 
PRES:  La presión va de 1003 a 1019 con una moda de 1009.
Iws:   La velocidad del viento va de 0.89 a 166.73 con una moda de 1.79 con el 75% de los datos menores a 15.6 lo cual indica que hay entre moderado y bajo viento. 
Is:    No hay nieve.
Ir:    De 3 a 13.

Cluster 7: "Otoño, temperatura templada y vientos moderados, mayor lluvia. Contaminación *buena-moderada*"
Año :2014
Mes :9
CBWD:NW


Hora:  MODA: 11:00, el 50% de los datos estan entre las 11:00am y las 14:00. Mañana-tarde.
pm2.5: Los datos van de 8 a 75 con moda= 22 y el 75% de los datos son menores a 39. Contaminaci?n baja.
DEWP:  El grado de humedad va de 10 a 17 grados con una moda de 10. Lo cual es medianamente húmedo y el 75% de los datos son menores a 17.
TEMP:  La temperatura va de 12 a 18 grados con una moda de 18, lo cual indica clima templado con el 75% de los datos menores a 18? 
PRES:  La presi?n va de 1002 a 1018 con una moda de 1016.
Iws:   La velocidad del viento va de 0.89 a 26.83 con una moda de 0.89 con el 
75% de los datos menores a 12.3 lo cual indica que hay entre medio-bajo y alto viento. 
Is:    No hay nieve.
Ir:    de 13 a 23, con moda 14. Es el cluster más lluvioso.


###Preguntas

1. k-means

    + Cuántos grupos generaste, justificación 
    Generamos 7 grupos basados en la técnica "del codo", ya que al llegar a 7 grupos aún nos proporcionaba bastante información, pero el cambio de 7 a 8 aportaba muy poca.
    + Caracter??sticas de cada grupo *En la página anterior
    + Centroides obtenidos
```{r echo = FALSE}
k_7$centers
```
    + ¿Cuántos elementos hay por grupo? 

Cluster 1: `r nrow(cluster1)`

Cluster 2: `r nrow(cluster2)`

Cluster 3: `r nrow(cluster3)`

Cluster 4: `r nrow(cluster4)`

Cluster 5: `r nrow(cluster5)`

Cluster 6: `r nrow(cluster6)`

Cluster 7: `r nrow(cluster7)`
    
    + ¿Los grupos están balanceados? 
En general sí, pero no están bien balanceados. El cluster 2 tiene muy pocos datos, únicamente 161. Mientras que el mayor (cluster 4) tiene 10,570. En promedio tienen 5,964 observaciones.
    
    
2. Dendogramas

    + ¿Cuántos elementos hay por grupo? 
    
Cluster 1: `r n1`

Cluster 2: `r n2`

Cluster 3: `r n3`

Cluster 4: `r n4`

Cluster 5: `r n5`

Cluster 6: `r n6`

Cluster 7: `r n7`
    
    + ¿Los grupos están balanceados? 
    NO, tenemos un grupo muy grande y los demás son más pequeños 
    
    + Características de cada grupo
    Se encuentran en la pestaña anterior
    
    
3. Diferencias entre las características de cada grupo

La primer diferencia que podemos encontrar entre los 2 modelos, es que en los k-means cada uno de los clusters contenía un número de nodos, si bien no totalmente balanceados, pero la diferencia numérica entre ellos no fue tan relevante. En cambio, en los dendogramas pudimos ver que encontrar 1 punto balanceado que no requiera de un número excesivo de clusters era básicamente imposible. Como se puede observar en el gráfico del dendograma que creamos, pues esto crea un sesgo dando como resultado que casi la totalidad de las observaciones cayeran en un solo cluster dejando a los demás con solo unas cuantas.
Por lo tanto, los grupos creados con k-means nos ofrecen mucha m?s confiabilidad al momento de agrupar los datos, sin embargo, el modelo generado por los dendogramas cuenta con grupos que pueden representar temperaturas m?s extremas, y que se encuentran con valores de las distintas variables mucho más agrupados.  

En consecuencia, creemos que cada modelo puede ocuparse para diferentes funciones. El k-means nos permitió agrupar observaciones con características similares, pero con variaciones mucho mayores, en cambio, los dendogramas nos permitieron nidentificar pequeños puntos, en los cuales la informaci?n destacaba en gran medida a la gran mayoría de las mismas, por lo tanto, con este modelo podríamos identificar observaciones muy especiales, pero, para ciertos prop?sitos generales, su uso podría no tener ningún beneficio.

###Conclusiones

En los dendogramas fue donde obtuvimos dos cluster que únicamente contenían observaciones con contaminación buena o moderada, por lo que consideramos que éstos tienen las características que más probablemente indicarán que un día será saludable en Beijing. Estas características, como pensamos al inicio del análisis tienen que ver con vientos altos, temperaturas moderadas y lluvia. 

Además, los clusters que contenían los datos más peligrosos de pm2.5 fueron 